<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Deep Learning for Patient-Independent Epileptic Seizure Prediction Using Scalp EEG Signals</title>
      <link href="/2021/07/01/Deep-Learning-for-Patient-Independent-Epileptic-Seizure-Prediction-Using-Scalp-EEG-Signals/"/>
      <url>/2021/07/01/Deep-Learning-for-Patient-Independent-Epileptic-Seizure-Prediction-Using-Scalp-EEG-Signals/</url>
      
        <content type="html"><![CDATA[<h3 id="overview">Overview</h3><div data-align="center"><p><img src="/2021/07/01/Deep-Learning-for-Patient-Independent-Epileptic-Seizure-Prediction-Using-Scalp-EEG-Signals/1.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><p>优点：通过对subject的身份判别来实现subject independent(SI)，很新颖，也抓住了问题的本质。</p><p>缺点：Siamese还不是终点，还可以通过别的方法去辨别不同的subject。</p><p>兴趣程度：9</p><span id="more"></span><h3 id="understanding">Understanding</h3><p>这篇文章提出了两个网络结构，第一个纯CNN，第二个是Siamese。做SI的方法是，通过训练网络，先判别某个EEG信号来自哪个subject。当网络训练好之后，就可以提取出每个subject的unique的characteristics。这对做SI很有帮助，SI是想让网络有泛化能力，针对不同subject各异的信号输入，都能给出相对一致(结果)的输出，可以对症下药。如果说网络已经获得了characteristics，那么下一步对症下药就会容易很多。比如说用GAN来生成具有common characteristic的信号，然后不断强化。比如说，输入是subject的信号，然后给他分析一波，unique的成分去掉，看看common的是什么东西，去做prediction。</p><div data-align="center"><p><img src="/2021/07/01/Deep-Learning-for-Patient-Independent-Epileptic-Seizure-Prediction-Using-Scalp-EEG-Signals/2.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><p>网络本身不复杂，但是这个思想感觉是很新颖，并且一针见血的。然后实验部分，有个SHAP模型，用来衡量信号各个component的贡献，可以参考。</p><div data-align="center"><p><img src="/2021/07/01/Deep-Learning-for-Patient-Independent-Epileptic-Seizure-Prediction-Using-Scalp-EEG-Signals/3.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><h3 id="analysis">Analysis</h3><p>值得研究。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Subject Independent BCI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Brain-Controlled Robotic Arm System Based on Multi-Directional CNN-BiLSTM Network Using EEG Signals</title>
      <link href="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/"/>
      <url>/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/</url>
      
        <content type="html"><![CDATA[<h3 id="overview">Overview</h3><div data-align="center"><p><img src="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/1.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><p>优点：regression的训练模式，第一次见</p><p>缺点：略微简单，没有subject independent</p><p>兴趣程度：7</p><span id="more"></span><h3 id="understanding">Understanding</h3><p>这篇文章的思路是，事先用实验数据拿到一个ground truth，然后train dataset去拟合这个gt。文章里面是这样说的：</p><blockquote><p>In our experiment, the robotic arm performed reaching tasks according to the directions given in order to acquire the baseline velocity profile after the sessions.</p><p>Conventional hybrid deep learning frameworks have been commonly trained to extract spatial features of brain activities using a CNN and have been trained with temporal information using LSTM networks. In contrast, the proposed MDCBN framework was designed using a CNN architecture to train the multi-direction information per axis as <strong>pretraining</strong> and it used the BiLSTM network for training the <strong>relationships</strong> in the 3D space (x-, y-, and z-axes).</p></blockquote><div data-align="center"><p><img src="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/2.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><p>所以CNN只是一个特征提取模块，然后用BiLSTM去获取xyz三个维度的关系，最后和gt做regression。</p><div data-align="center"><p><img src="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/3.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><h3 id="analysis">Analysis</h3><p>这是第一篇涉及robotic arm的文章，还不知道这样的方法算不算新颖。还有一个问题就是，这个gt是由robotic arm自己运动产生的，然后让EEG信号通过网络，去拟合这个曲线，略微有点说不通。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Robotic Arm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DSNet: A Flexible Detect-to-Summarize Network for Video Summarization</title>
      <link href="/2021/05/24/DSNet/"/>
      <url>/2021/05/24/DSNet/</url>
      
        <content type="html"><![CDATA[<h3 id="Overview">Overview</h3><p>代码：<a href="https://github.com/li-plus/DSNet">https://github.com/li-plus/DSNet</a></p><p>兴趣程度： 6</p><span id="more"></span><h3 id="Details">Details</h3><p><img src="/images/DSNet/2.png" alt=""></p><p><img src="/images/DSNet/3.png" alt=""></p><p><img src="/images/DSNet/6.png" alt=""></p><p><img src="/images/DSNet/7.png" alt=""></p><p><img src="/images/DSNet/8.png" alt=""></p><p><img src="/images/DSNet/9.png" alt=""></p><p><img src="/images/DSNet/10.png" alt=""></p><p><img src="/images/DSNet/11.png" alt=""></p><p><img src="/images/DSNet/12.png" alt=""></p><p><img src="/images/DSNet/13.png" alt=""></p><p><img src="/images/DSNet/14.png" alt=""></p><p><img src="/images/DSNet/15.png" alt=""></p><p><img src="/images/DSNet/16.png" alt=""></p><p><img src="/images/DSNet/17.png" alt=""></p><p><img src="/images/DSNet/18.png" alt=""></p><p><img src="/images/DSNet/19.png" alt=""></p><p><img src="/images/DSNet/20.png" alt=""></p><p><img src="/images/DSNet/21.png" alt=""></p><p><img src="/images/DSNet/22.png" alt=""></p><p><img src="/images/DSNet/23.png" alt=""></p><p><img src="/images/DSNet/24.png" alt=""></p><p><img src="/images/DSNet/25.png" alt=""></p><p><img src="/images/DSNet/26.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
            <tag> Video Summarization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization</title>
      <link href="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/"/>
      <url>/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/</url>
      
        <content type="html"><![CDATA[<h3 id="Overview">Overview</h3><div align="center">  <img src="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.png" width="70%" height="70%" alt="BiLSTM" align="center"></div><p>优点：frame-shot-video分层结构，双向LSTM滑动窗口</p><p>缺点：纯pixel features，supervised，importance score不新颖，滑动窗口k固定</p><p>兴趣程度：6</p><span id="more"></span><h3 id="Understanding">Understanding</h3><p>中规中矩的一篇文章。提出了frame-shot-video的层级结构。先从frames中划分shots，再再划分的shots中，选择key shots。优点在于，单个shots的长度和shots的个数可变不固定，问题是默认了一个滑动窗口中必然出现shot boundary，这个是不一定的。选confidence score是用softmax的形式（n取1）。选shot boundary和key shot用的是一样的方法。</p><h3 id="Analysis">Analysis</h3><p>由于这篇文章需要label，标记正确key shots的位置来训练，所以还有待改进。说到底，还是没有真正找到frames（shots）在高维空间中的联系（loss function），所以只能有监督。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
            <tag> Video Summarization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Unsupervised Video Summarization via Relation-aware Assignment Learning</title>
      <link href="/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/"/>
      <url>/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/</url>
      
        <content type="html"><![CDATA[<h3 id="0-Overview">0. Overview</h3><div align="center">  <img src="/images/Unsupervised Video Summarization via Relation-aware Assignment Learning/2.png" width="70%" height="70%" alt="BiLSTM" align="center"></div><p>优点：使用GNN来表达relation，unsupervised<br>缺点：clip的划分，loss的选取，纯pixel提取<br>兴趣程度：7</p><h3 id="1-Understanding">1. Understanding</h3><p>将一个视频分成等长的n个clips，e.g. 10000帧的视频分成等长的20个clips，每个clip包含500帧。每个clip feature作为GNN中的一个node。node之间的edge关系，不是用邻接矩阵表示，而且用全连接的网络得到。node之间传递信息的时候，也是用全连接，把edge的信息当作先验，更新node。<br>MLP是为了进一步提取feature，经过MLP后，得到n个更加representative的feature clips。用L2 norm得到它们的importance score（这边应该是通过node间的联系紧密程度来得到的），然后取前k个作为summary embedding其他为non-summary embedding。另外GNN中所有node合起来得到video embedding，这三个embedding一起放入loss。用了triplet loss，想拉近v和s，拉远v和n。</p><h3 id="2-Analysis">2. Analysis</h3><p>可部分参考。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> Video Summarization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning on Attribute-Missing Graphs</title>
      <link href="/2020/12/29/Learning-on-Attribute-Missing-Graphs/"/>
      <url>/2020/12/29/Learning-on-Attribute-Missing-Graphs/</url>
      
        <content type="html"><![CDATA[<h3 id="introduction">0. Introduction</h3><div data-align="center"><p><img src="/images/Learning-on-Attribute-Missing-Graphs/structure.png" width="70%" height="70%" alt="BiLSTM" align="center"></p></div><p>Paper link: https://arxiv.org/pdf/2011.01623.pdf</p><p>Code link: https://github.com/xuChenSJTU/SAT-master-online</p><p>主要分析一下算法部分，实验部分不涉及。是VAE+GAN应用于graph的一个文章。用了两个VAE，分别训练X(attribute)和A(structure)。文章假设X和A的<span class="math inline">\(z\)</span>在高维空间中遵从同一分布，然后用GAN对他们的高维分布<span class="math inline">\(z\)</span>进行加强。</p><h3 id="vae">1. VAE</h3><p>普通的AE只要，求两个分布p和q使得： <span class="math display">\[\hat x \approx q(z)\\z = p(x)\]</span> 但是实际上操作，有很多局限性。VAE对<span class="math inline">\(z\)</span>做限制，使其遵从某个分布，这样如果直接sample一个这个分布给他作为<span class="math inline">\(q(x)\)</span>的输入，就可以得到一个相对纯AE来说不错的结果。<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>是两个NN。</p><p>VAE先推导一下。手上有一堆观测数据<span class="math inline">\(x\)</span>，现在要求他们的分布<span class="math inline">\(p(x)\)</span>。由于分布可能非常复杂，这里用GMM来表示。假设<span class="math inline">\(x\)</span>由一个隐变量<span class="math inline">\(z\)</span>控制。那么有 <span class="math display">\[p(x)=\int_z p(x|z)p(z)\]</span> 接下来就是要求<span class="math inline">\(p(x)\)</span>的MLE。即maximize <span class="math display">\[L=\sum_x logp(x)\]</span> 做个恒等变形， <span class="math display">\[\begin{equation}\begin{split}logp(x)&amp;=\int_z q(z|x)log~p(x)dz=\int_z q(z|x)log\frac{p(x,z)}{p(z|x)}dz \\&amp;=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz+\int_z q(z|x)log\frac{q(z|x)}{p(z|x)}dz \\&amp;=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz +KL(q(z|x)||p(z|x))\\&amp;\ge \int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz=\int_z q(z|x)log\frac{p(x|z)p(z)}{q(z|x)}dz=L_b\end{split}\nonumber\end{equation}\]</span> 因而，就是要maximize<span class="math inline">\(L_b\)</span>，而 <span class="math display">\[\begin{equation}\begin{split}L_b&amp;=\int_z q(z|x)log\frac{p(z)}{q(z|x)}dz+\int_z q(z|x)logp(x|z)dz\\&amp;=-KL(q(z|x)||p(z))+\int_z q(z|x)logp(x|z)dz\end{split}\nonumber\end{equation}\]</span> 即minimize前者，maximize后者。前者只需训练 encoder <span class="math inline">\(q\)</span> 让他输出的分布 <span class="math inline">\(z\)</span> 接近 <span class="math inline">\(p(z)\)</span> 即可。后者可写成 <span class="math display">\[E_{x\sim q(z|x)}p(x|z)\]</span> 即普通AE的工作。</p><h3 id="sat">2. SAT</h3><p>VAE+GAN的组合并不新鲜，但是这篇文章把它运用于重构图的节点信息，算是一个创新点。<span class="math inline">\(X\)</span>表示的是每个node的attribute，<span class="math inline">\(A\)</span>是整个图的structure。用两个VAE用于分别重构attribute和structure。其中，<span class="math inline">\(E_x\)</span>、<span class="math inline">\(D_x\)</span>、<span class="math inline">\(D_A\)</span>是MLP，而<span class="math inline">\(E_A\)</span>是GNN，其中的原因不是很懂。这篇文章是基于一个假设的，即：</p><blockquote><p>In graph structured data, each node’s attributes and structures are correlated together and can be represented in a shared-latent space.</p></blockquote><p>因为如果不这样，就不能让两个VAE通过隐变量<span class="math inline">\(z\)</span>互相学习了。不过这个假设背后的数学原理（是否有），目前还不懂，但这个假设是非常关键的一步。所以<span class="math inline">\(z\)</span>其实是一个桥梁，充当了两个角色，1）<span class="math inline">\(E_x-&gt;z-&gt;D_A\)</span>和<span class="math inline">\(E_A-&gt;z-&gt;D_x\)</span>；2）<span class="math inline">\(z_A\)</span>和<span class="math inline">\(z_X\)</span>的分布用GAN去拟合。所以这个VAE+GAN和之前有篇VAE-GAN本质上不一样，之前的是用GAN去强化<span class="math inline">\(x\)</span>和<span class="math inline">\(\hat x\)</span>，使单个VAE的表现更好，图像更清晰，而这篇文章是用GAN去使两个<span class="math inline">\(z\)</span>遵从同一分布。</p><p>最后贴一下损失函数作为总结，首先是VAE部分的， <span class="math display">\[\begin{equation}\begin{split}min_{\theta_x,\theta_a,\phi_x,\phi_a}L_r =&amp;− E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[logp_{\theta_x}(x_i|z_x)]]\\&amp;− E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_a}(a_i|z_a)]]\\&amp;− λ_c · E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_x}(x_i|z_a)]]\\&amp;− λ_c · E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[log p_{\theta_a}(a_i|z_x)]]\end{split}\nonumber\end{equation}\]</span> 其中，<span class="math inline">\(\lambda_c\)</span>是调节上下两个的权重的。接下来是GAN的， <span class="math display">\[\begin{equation}\begin{split}min_\psi max_{\phi_x,\phi_a} L_{adv} = &amp;− E_{z_p\sim p(z)}[log D(z_p)]\\&amp;− E_{z_x\sim q_{\phi_x}(z_x|x_i)}[log(1 − D(z_x))]\\&amp;− E_{z_p\sim p(z)}[log D(z_p)]\\&amp;− E_{z_a\sim q_{\phi_a}(z_a|a_i)}[log(1 − D(z_a))]\end{split}\nonumber\end{equation}\]</span> 其中，<span class="math inline">\(\psi\)</span>是D的参数，<span class="math inline">\(z_p\)</span>是label，来自某个分布，这里是Gaussian。最后是总的。 <span class="math display">\[min_\Theta max_\Phi L = L_r + L_{adv}\]</span> 其中，<span class="math inline">\(\Theta = \{\theta_x, \theta_a, \phi_x, \phi_a, \psi\}\)</span> ，$ Φ = {_x, _a}$。</p>]]></content>
      
      
      <categories>
          
          <category> Paper Reading </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pip 镜像加速</title>
      <link href="/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/"/>
      <url>/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/</url>
      
        <content type="html"><![CDATA[<h3 id="临时指定源">1.临时指定源</h3><div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># xxxxxxx 为安装对象</span></span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install -i https://pypi.tuna.tsinghua.edu.cn/simple xxxxxxx</span></code></pre></div><p><br></p><h3 id="永久设定">2.永久设定</h3><div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a> <span class="co"># Linux   下创建或进入</span></span><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a> <span class="co"># ~/.pip/pip.conf </span></span><span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a> [<span class="ex">global</span>]</span><span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a> <span class="ex">index-url</span> = https://pypi.tuna.tsinghua.edu.cn/simple</span><span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a> </span><span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a> <span class="co"># Windows 下创建或进入</span></span><span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a> <span class="co"># C:/User/xxxxxxx/pip/pip.ini</span></span><span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a> [<span class="ex">global</span>]</span><span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a> <span class="ex">index-url</span> = https://pypi.tuna.tsinghua.edu.cn/simple</span></code></pre></div>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 下载加速 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>终端加速</title>
      <link href="/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/"/>
      <url>/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/</url>
      
        <content type="html"><![CDATA[<pre><code># Port number may vary # Linux (electron_ssr)export http_proxy=http://127.0.0.1:12333export https_proxy=http://127.0.0.1:12333export http_proxy=socks5://127.0.0.1:12333export https_proxy=socks5://127.0.0.1:12333# Windows (cmd)(git)set http_proxy=http://127.0.0.1:1080set https_proxy=http://127.0.0.1:1080set http_proxy=socks5://127.0.0.1:1080set https_proxy=socks5://127.0.0.1:1080</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 下载加速 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LSF 作业调度系统</title>
      <link href="/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h3 id="intro">0. Intro</h3><p>最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。</p><h3 id="os-software">1. OS &amp; Software</h3><p>Windows 10 ( Linux 下没有 GUI，用 FTP 传文件还是不方便，用 windows 的话就是直接文件交互比较方便 )</p><p>软件用的是 MobaXterm。</p><h3 id="command-list">2. Command List</h3><h4 id="bsub-lsf.sh">bsub &lt; lsf.sh</h4><p>其中， lsf.sh 是自己写的一个脚本，之前犯错没输 &lt;, 然后提交总是通不过。脚本范例如下：</p><pre><code># !/bin/sh# BSUB -q gpu_v100# BSUB -m "gpu10"# BSUB -gpu num=4:mode=exclusive_process# BSUB -o %J.out# BSUB -n 1# BSUB -e %J.err# BSUB -J Firsttrypython3 /xxx/xxx/xxx/xxx.py</code></pre><h4 id="bjobs">bjobs</h4><p>该指令可以查看当前正在运行的作业。</p><p><img src="/images/LSF作业调度系统/bjobs.jpg"></p><h4 id="bjobs--l-job_id">bjobs -l JOB_ID</h4><p>该指令可以查看当前正在运行的作业的详细情况。</p><p><img src="/images/LSF作业调度系统/bjobs-l.jpg"></p><h4 id="bjobs--p-job_id">bjobs -p JOB_ID</h4><p>该指令可以查看作业 PENDING 的原因。</p><p><img src="/images/LSF作业调度系统/bjobs-p.jpg"></p><h4 id="bkill-job_id">bkill JOB_ID</h4><p>该指令可以结束作业。</p><p><img src="/images/LSF作业调度系统/bkill.jpg"></p><h4 id="bkill--r-job_id">bkill -r JOB_ID</h4><p>由于刚接触 LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么 bkill 都结束不了作业，然后输入 info bkill 查看了一下它的详细用法。这个可以直接杀死进程。</p><p><img src="/images/LSF作业调度系统/bkill-r.jpg"></p><h4 id="bstop-job_id-与-bresume-job_id">bstop JOB_ID** 与 **bresume JOB_ID</h4><p>挂起和恢复作业，一般不用。如果作业不想继续了，最好直接 kill，否则占用资源。</p><h4 id="bpeek-job_id-与-bpeek--f-job_id">bpeek JOB_ID 与 bpeek -f JOB_ID</h4><p>该指令可以显示程序当前的屏幕输出。</p><p><img src="/images/LSF作业调度系统/bpeek.jpg"></p><h4 id="lsload-与-lsload--gpuload">lsload 与 lsload -gpuload</h4><p>该指令可以输出负载。</p><p><img src="/images/LSF作业调度系统/lsload.jpg"></p><h4 id="bhosts-与-bqueues">bhosts 与 bqueues</h4><p>该指令可以查看各个节点和队列的作业信息。</p><p><img src="/images/LSF作业调度系统/bhosts.jpg"></p><p><img src="/images/LSF作业调度系统/bqueues.jpg"></p><h3 id="ending">3. Ending</h3><p>最后祝自己以后还有机会用这样的 GPU 集群。:)</p>]]></content>
      
      
      <categories>
          
          <category> Thinking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN</title>
      <link href="/2020/02/17/GAN/"/>
      <url>/2020/02/17/GAN/</url>
      
        <content type="html"><![CDATA[<h3 id="description">0. Description</h3><p>这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理.</p><h3 id="gan">1. GAN</h3><p>最初 GAN 的目的是想 generate 出和真实图片非常像的图片. 有个有个图片集 data, 假设它在某维空间满足某个分布:</p><div data-align="center"><p><img src="/images/GAN/1.png" width="50" height="35" align="center"></p></div><p>但是现在不知道这个分布的 formula, 现在可以做的是从这个 data 的分布中, sample 出一些图片. Generator 就希望能通过 network 学到一个分布:</p><div data-align="center"><p><img src="/images/GAN/2.png" width="33" height="33" align="center"></p></div><p>希望得到:</p><div data-align="center"><p><img src="/images/GAN/3.png" width="110" height="38" align="center"></p></div><p>也就是说, 当这两个分布相等时, 随便从 generator 学到的 distribution 中 sample 产生一个图片, 都会是在 data 的distribution 中的, 也就是说会是真实的图片.</p><p>因为 generator 是个 network, 所以它要做的就是学到一个 network, 使得这两个分布的 divergence 最小:</p><div data-align="center"><p><img src="/images/GAN/4.png" width="370" height="40" align="center"></p></div><p>由于这两个分布它们的 formula 都不知道, 所以 divergence 其实是不能直接算的. 这个时候先把这个问题放一边, 看一下 discriminator.</p><p>Discriminator 要做的事情是区分真实的 image 和 generated 的 image. 如果是从 data distribution 中 sample 出来的, 就给高分; 如果是从 generated distribution 中 sample 出来的, 就给低分:</p><div data-align="center"><p><img src="/images/GAN/7.png" width="265" height="45" align="center"></p></div><p>所以可以得到以下 cost function, 希望 V 越大越好, 已经经过了一部分等价转换:</p><div data-align="center"><p><img src="/images/GAN/5.png" width="570" height="40" align="center"></p></div><p>把期望转成积分的形式:</p><div data-align="center"><p><img src="/images/GAN/6.png" width="550" height="42" align="center"></p></div><p>预期是, 无论输入什么样的 x, 只要来自于 generator 就给低分, 只要来自于 real sample 就给高分, 所以其实 D of x 的在某处(e.g. x = 0)的值不受任何附近(e.g. (-1, 1))的值的影响, 完全可以看成是一元函数求极值.</p><div data-align="center"><p><img src="/images/GAN/8.png" width="270" height="53" align="center"></p></div><p>最后算出来, 理论上 D 取这个值的时候 V 可以达到最大, 也就是说 discriminator 的性能最好. 但是两个分布都不知道, 所以没有解析解, 真正操作时这个用不了. 但是把上式代入 V 中, 整理后可得:</p><div data-align="center"><p><img src="/images/GAN/9.png" width="600" height="50" align="center"></p></div><p>发现这个正好是 JS divergence 的形式. 又由于最初要求的就是 g 和 data distribution 的 divergence, 所以把上式代入 G star 得:</p><div data-align="center"><p><img src="/images/GAN/10.png" width="320" height="52" align="center"></p></div><p>这个式子就可以用 network 求了. 先固定 Generator 训练 Discriminator 让 V 达到 max, 再固定 Discriminator 训练 Generator 使得 V 取最小值. Iteratively 训练.</p><pre><code>import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchos.makedirs("images", exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")parser.add_argument("--img_size", type=int, default=28, help="size of each image dimension")parser.add_argument("--channels", type=int, default=1, help="number of image channels")parser.add_argument("--sample_interval", type=int, default=400, help="interval betwen image samples")opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass Generator(nn.Module):    def __init__(self):        super(Generator, self).__init__()        def block(in_feat, out_feat, normalize=True):            layers = [nn.Linear(in_feat, out_feat)]            if normalize:                layers.append(nn.BatchNorm1d(out_feat, 0.8))            layers.append(nn.LeakyReLU(0.2, inplace=True))            return layers        self.model = nn.Sequential(            *block(opt.latent_dim, 128, normalize=False),            *block(128, 256),            *block(256, 512),            *block(512, 1024),            nn.Linear(1024, int(np.prod(img_shape))),            nn.Tanh()        )    def forward(self, z):        img = self.model(z)        img = img.view(img.size(0), *img_shape)        return imgclass Discriminator(nn.Module):    def __init__(self):        super(Discriminator, self).__init__()        self.model = nn.Sequential(            nn.Linear(int(np.prod(img_shape)), 512),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(512, 256),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(256, 1),            nn.Sigmoid(),        )    def forward(self, img):        img_flat = img.view(img.size(0), -1)        validity = self.model(img_flat)        return validity# Loss functionadversarial_loss = torch.nn.BCELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda:    generator.cuda()    discriminator.cuda()    adversarial_loss.cuda()# Configure data loaderos.makedirs("../../data/mnist", exist_ok=True)dataloader = torch.utils.data.DataLoader(    datasets.MNIST(        "../../data/mnist",        train=True,        download=True,        transform=transforms.Compose(            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]        ),    ),    batch_size=opt.batch_size,    shuffle=True,)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor# ----------#  Training# ----------for epoch in range(opt.n_epochs):    for i, (imgs, _) in enumerate(dataloader):        # Adversarial ground truths        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)        # Configure input        real_imgs = Variable(imgs.type(Tensor))        # -----------------        #  Train Generator        # -----------------        optimizer_G.zero_grad()        # Sample noise as generator input        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))        # Generate a batch of images        gen_imgs = generator(z)        # Loss measures generator's ability to fool the discriminator        g_loss = adversarial_loss(discriminator(gen_imgs), valid)        g_loss.backward()        optimizer_G.step()        # ---------------------        #  Train Discriminator        # ---------------------        optimizer_D.zero_grad()        # Measure discriminator's ability to classify real from generated samples        real_loss = adversarial_loss(discriminator(real_imgs), valid)        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)        d_loss = (real_loss + fake_loss) / 2        d_loss.backward()        optimizer_D.step()        print(            "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())        )        batches_done = epoch * len(dataloader) + i        if batches_done % opt.sample_interval == 0:            save_image(gen_imgs.data[:25], "images/%d.png" % batches_done, nrow=5, normalize=True)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Theoretical Analysis </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>sorted 对 class 元素排序</title>
      <link href="/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/"/>
      <url>/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="example">Example</h3><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> unit(<span class="bu">object</span>):</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, value, label):</span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> value</span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label</span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        </span><span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        </span><span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> [unit(<span class="va">None</span>, <span class="va">None</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span><span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 对a赋值后</span></span><span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># reverse = True 降序, 默认为 False 升序</span></span><span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="bu">sorted</span>(a, key<span class="op">=</span><span class="kw">lambda</span> student: student.value, reverse <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div><h3 id="student-可随便换其他名字">student 可随便换其他名字</h3>]]></content>
      
      
      <categories>
          
          <category> Practical Codes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mAP CMC</title>
      <link href="/2020/02/12/mAP-CMC/"/>
      <url>/2020/02/12/mAP-CMC/</url>
      
        <content type="html"><![CDATA[<h2 id="mapmean-average-precision">mAP<strong>(Mean Average Precision)</strong></h2><h3 id="tp-fn-tn-fp">0. TP &amp; FN &amp; TN &amp; FP</h3><h4 id="tp-是-true-positive-表示正样本被判断为正样本即t-true.-fn-是-false-negative-表示-negative-sample-被判断为-positive-sample-即f-false.-另外两个也一样.">TP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样.</h4><h3 id="precision-recall">1. Precision &amp; Recall</h3><h4 id="分类问题中-现在已有每个样本的概率值和标签-0-1.-将样本按照概率从高到底排序.-分类器表现理想的情况是-标签为-1-的样本都在上面-标签为-0-的样本都在下面.-有个-threshold-一开始指向最上面的-sample-然后每次下移一个-threshold-及以上的都被认为是-positive-sample-下面的都被认为是-negative-sample.">分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及以上的都被认为是 positive sample, 下面的都被认为是 negative sample.</h4><h4 id="precision-tp-tp-fn-假设-tp-fn-k-precision-就表示前-k-个样本中-negative-sample-的比例-因为它们本来应该呆在-positive-sample-下面的-但它们现在跑到-positive-sample-上面去了.-有几个-positive-sample-就计算几个-precision-threshold-每次下移一个-当移到某个-sample-为-positive-sample-的时候再算-precision.">Precision = TP / (TP + FN) 假设 TP + FN = k, precision 就表示前 k 个样本中, "negative sample 的比例", 因为它们本来应该呆在 positive sample 下面的, 但它们现在跑到 positive sample 上面去了. 有几个 positive sample 就计算几个 precision, threshold 每次下移一个, 当移到某个 sample 为 positive sample 的时候再算 precision.</h4><h4 id="recall-tp-tp-fp-表示-positive-sample-被成功找回来的概率.-因为-positive-sample-总数不变-所以-tp-fp-不变.-recall-最终会为1.">Recall = TP / (TP + FP) 表示 positive sample 被成功找回来的概率. 因为 positive sample 总数不变, 所以 TP + FP 不变. Recall 最终会为1.</h4><h3 id="ap-map">2. AP &amp; mAP</h3><h4 id="假设有">假设有</h4><p><span class="math display">\[AP =\frac{\sum^N_1 precision}{N}\]</span></p><p><br></p><h2 id="cmccumulative-match-characteristics">CMC<strong>(Cumulative Match Characteristics)</strong></h2><h3 id="section"></h3><p><br></p>]]></content>
      
      
      <categories>
          
          <category> Metrics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Image.convert转化图片</title>
      <link href="/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/"/>
      <url>/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<div class="sourceCode" id="cb1"><pre class="sourceCode restructuredtext"><code class="sourceCode rest"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a> 1 ------------------（1位像素，黑白，每字节一个像素存储）</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a> L ------------------（8位像素，黑白）</span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> P ------------------（8位像素，使用调色板映射到任何其他模式）</span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a> RGB-------------- （3x8位像素，真彩色）</span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a> RGBA-------------（4x8位像素，带透明度掩模的真彩色）</span><span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a> CMYK-------------（4x8位像素，分色）</span><span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a> YCbCr------------ （3x8位像素，彩色视频格式）</span><span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a> I--------------------（32位有符号整数像素）</span><span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> F------------------- （32位浮点像素）</span></code></pre></div><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'1'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/a.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'L'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/b.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'P'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/c.png" width="320" height="240" align="center"></p></div><pre><code>img = Image.open(path).convert('RGB')</code></pre><div data-align="center"><p><img src="/images/Image.convert转化图片/d.png" width="320" height="240" align="center"></p></div><pre><code>img = Image.open(path).convert('RGBA')</code></pre><div data-align="center"><p><img src="/images/Image.convert转化图片/e.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'CMYK'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/f.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'YCbCr'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/g.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'I'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/h.png" width="320" height="240" align="center"></p></div><div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(path).convert(<span class="st">'F'</span>)</span></code></pre></div><div data-align="center"><p><img src="/images/Image.convert转化图片/k.png" width="320" height="240" align="center"></p></div>]]></content>
      
      
      <categories>
          
          <category> Practical Codes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>模型的保存与载入</title>
      <link href="/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/"/>
      <url>/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<h3 id="跑大网络一次跑不完就要保存了下次再跑有两种保存方式一种是保存网络基本结构e.g.-每层的w-b一种是整个网络所有东西全部保存网上推荐使用第一种因为如果网络过大用第二种方法加载网络会比较慢而且占地方也大我只试过第一种pytorch-例子如下">跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。</h3><p><br></p><h3 id="保存">保存：</h3><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>torch.save(net.state_dict(), model_path <span class="op">+</span> <span class="st">'/model-inter-'</span> <span class="op">+</span> <span class="bu">str</span>(batch_id<span class="op">+</span><span class="dv">1</span>) <span class="op">+</span> <span class="st">".pt"</span>)</span></code></pre></div><p><br></p><h3 id="加载-map_location-要写清楚用的是-cpu-还是-gpu用的是哪几块不然可能会报错">加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：</h3><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Siamese()</span><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>net.load_state_dict(torch.load(<span class="st">'/home/yk/siamese-pytorch/models/model-inter-104001.pt'</span>, map_location<span class="op">=</span><span class="st">'cuda:0'</span>)</span></code></pre></div>]]></content>
      
      
      <categories>
          
          <category> Practical Codes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>制作自己的 dataset</title>
      <link href="/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/"/>
      <url>/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/</url>
      
        <content type="html"><![CDATA[<h3 id="制作自己的-dataset-要写一个自己的-dataset-类然后用-dataloader-封装就好了">制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader 封装就好了。</h3><hr><h1 id="一dataset-制作">一、Dataset 制作</h1><h3 id="一般-dataset-类有以下的函数">一般 Dataset 类有以下的函数：</h3><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Dataset(Dataset):</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, ...):</span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        ...</span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span><span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        ...</span><span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span><span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        ...</span><span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div><p><br></p><h3 id="init__-是初始化时传入的一些参数不是非常重要">__init__() 是初始化时传入的一些参数，不是非常重要。</h3><h3 id="getitem__-需要自己修改功能是将图片从磁盘中读入存入-array-或者-list-中">__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。</h3><h3 id="len__-是返回-dataset-的大小需要仔细设计">__len()__ 是返回 Dataset 的大小，需要仔细设计。</h3><h3 id="下面是两个用于构建siamese-nerual-network-的-example">下面是两个用于构建Siamese Nerual Network 的 example 。</h3><h3 id="这个是事先将图片的-path-都写入了一个-txt-文件中然后-getitem-就从-txt-中读图片路径">这个是事先将图片的 path 都写入了一个 txt 文件中，然后 getitem 就从 txt 中读图片路径。</h3><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyDataset(Dataset):</span><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, txt, transform<span class="op">=</span><span class="va">None</span>, target_transform<span class="op">=</span><span class="va">None</span>, should_invert<span class="op">=</span><span class="va">False</span>):</span><span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span><span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_transform <span class="op">=</span> target_transform</span><span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.should_invert <span class="op">=</span> should_invert</span><span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.txt <span class="op">=</span> txt</span><span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span><span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        line <span class="op">=</span> linecache.getline(<span class="va">self</span>.txt, random.randint(<span class="dv">1</span>, <span class="va">self</span>.<span class="fu">__len__</span>()))</span><span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        line.strip(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span><span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        img0_list <span class="op">=</span> line.split()</span><span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 判断是否要选同一个类别的图片</span></span><span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        should_get_same_class <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="dv">1</span>)</span><span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> should_get_same_class:</span><span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> <span class="va">True</span>:</span><span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                <span class="co"># 随机在 txt 中选一行读取，每一行有一张图片的 path 和它的 label</span></span><span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>                img1_list <span class="op">=</span> linecache.getline(<span class="va">self</span>.txt, random.randint(<span class="dv">1</span>, <span class="va">self</span>.<span class="fu">__len__</span>())).strip(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>).split()</span><span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> img0_list[<span class="dv">1</span>] <span class="op">==</span> img1_list[<span class="dv">1</span>]:</span><span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span><span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span><span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            img1_list <span class="op">=</span> linecache.getline(<span class="va">self</span>.txt, random.randint(<span class="dv">1</span>, <span class="va">self</span>.<span class="fu">__len__</span>())).strip(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>).split()</span><span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        img0 <span class="op">=</span> Image.<span class="bu">open</span>(img0_list[<span class="dv">0</span>])</span><span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        img1 <span class="op">=</span> Image.<span class="bu">open</span>(img1_list[<span class="dv">0</span>])</span><span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 转图片通道数</span></span><span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        img0 <span class="op">=</span> img0.convert(<span class="st">"L"</span>)</span><span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        img1 <span class="op">=</span> img1.convert(<span class="st">"L"</span>)</span><span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 非必要的</span></span><span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.should_invert:</span><span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>            img0 <span class="op">=</span> PIL.ImageOps.invert(img0)</span><span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>            img1 <span class="op">=</span> PIL.ImageOps.invert(img1)</span><span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 非必要的</span></span><span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span><span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>            img0 <span class="op">=</span> <span class="va">self</span>.transform(img0)</span><span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            img1 <span class="op">=</span> <span class="va">self</span>.transform(img1)</span><span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img0, img1, torch.from_numpy(np.array([<span class="bu">int</span>(img1_list[<span class="dv">1</span>] <span class="op">!=</span> img0_list[<span class="dv">1</span>])], dtype<span class="op">=</span>np.float32))</span><span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span><span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 这个 len 的返回长度就是 txt 中图片总数</span></span><span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span><span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        fh <span class="op">=</span> <span class="bu">open</span>(<span class="va">self</span>.txt, <span class="st">'r'</span>)</span><span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>        num <span class="op">=</span> <span class="bu">len</span>(fh.readlines())</span><span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        fh.close()</span><span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> num</span></code></pre></div><p><br></p><h3 id="这个是事先没有准备-txt-目录所以写了一个-loadtomem-去每个文件夹里面找图片">这个是事先没有准备 txt 目录，所以写了一个 loadToMem 去每个文件夹里面找图片。</h3><div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OmniglotTest(Dataset):</span><span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataPath, transform<span class="op">=</span><span class="va">None</span>, times<span class="op">=</span><span class="dv">100</span>, way<span class="op">=</span><span class="dv">166</span>):</span><span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="dv">1</span>)</span><span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(OmniglotTest, <span class="va">self</span>).<span class="fu">__init__</span>()</span><span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span><span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.times <span class="op">=</span> times</span><span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.way <span class="op">=</span> way</span><span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img1 <span class="op">=</span> <span class="va">None</span></span><span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c1 <span class="op">=</span> <span class="va">None</span></span><span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.datas, <span class="va">self</span>.num_classes <span class="op">=</span> <span class="va">self</span>.loadToMem(dataPath)</span><span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loadToMem(<span class="va">self</span>, dataPath):</span><span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"begin loading test dataset to memory"</span>)</span><span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># datas 是读取到的图片的总 list，idx 是类别数。</span></span><span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        datas <span class="op">=</span> {}</span><span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> <span class="dv">0</span></span><span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> alphaPath <span class="kw">in</span> os.listdir(dataPath):</span><span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># for charPath in os.listdir(os.path.join(dataPath, alphaPath)):</span></span><span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                datas[idx] <span class="op">=</span> []</span><span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> samplePath <span class="kw">in</span> os.listdir(os.path.join(dataPath, alphaPath)):</span><span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>                    filePath <span class="op">=</span> os.path.join(dataPath, alphaPath, samplePath)</span><span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>                    s <span class="op">=</span> Image.<span class="bu">open</span>(filePath).convert(<span class="st">'L'</span>)</span><span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># 调整图片尺寸</span></span><span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>                    s <span class="op">=</span> s.resize((<span class="dv">105</span>, <span class="dv">105</span>), Image.ANTIALIAS)</span><span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>                    datas[idx].append(s)</span><span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>                idx <span class="op">+=</span> <span class="dv">1</span></span><span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"finish loading test dataset to memory"</span>)</span><span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> datas, idx</span><span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span><span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.times <span class="op">*</span> <span class="va">self</span>.way</span><span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span><span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> index <span class="op">%</span> <span class="va">self</span>.way</span><span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">None</span></span><span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generate image pair from same class</span></span><span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span><span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.c1 <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="va">self</span>.num_classes <span class="op">-</span> <span class="dv">1</span>)</span><span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.img1 <span class="op">=</span> random.choice(<span class="va">self</span>.datas[<span class="va">self</span>.c1])</span><span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>            img2 <span class="op">=</span> random.choice(<span class="va">self</span>.datas[<span class="va">self</span>.c1])</span><span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generate image pair from different class</span></span><span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span><span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>            c2 <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="va">self</span>.num_classes <span class="op">-</span> <span class="dv">1</span>)</span><span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> <span class="va">self</span>.c1 <span class="op">==</span> c2:</span><span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>                c2 <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="va">self</span>.num_classes <span class="op">-</span> <span class="dv">1</span>)</span><span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>            img2 <span class="op">=</span> random.choice(<span class="va">self</span>.datas[c2])</span><span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span><span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span><span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>            img1 <span class="op">=</span> <span class="va">self</span>.transform(<span class="va">self</span>.img1)</span><span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>            img2 <span class="op">=</span> <span class="va">self</span>.transform(img2)</span><span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print('datas.shape = ', len(self.datas))</span></span><span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print('img1 = ', img1.shape)</span></span><span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print('img2 = ', img2.shape)</span></span><span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img1, img2</span></code></pre></div><p><br></p><hr><h1 id="二dataloader-封装">二、Dataloader 封装</h1><h3 id="这个比较简单因为-dataloader-是-pytorch-内置的函数">这个比较简单，因为 Dataloader 是 Pytorch 内置的函数。</h3><div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(dataset<span class="op">=</span>train_data, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>, batch_size<span class="op">=</span>Config.train_batch_size)</span></code></pre></div><p><br></p><h3 id="主要需要关注的是-batch_size-这个以及之前提到的-len-和训练的次数有关">主要需要关注的是 batch_size 。这个以及之前提到的 len 和训练的次数有关。</h3><div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(train_dataloader, <span class="dv">0</span>):</span></code></pre></div><p><br></p><h3 id="其中for-循环的次数-len-batch_size">其中，for 循环的次数 = len / batch_size 。</h3>]]></content>
      
      
      <categories>
          
          <category> Practical Codes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RuntimeError: size mismatch, m1: [128 x 184320], m2: [9216 x 4096]</title>
      <link href="/2019/11/30/size-mismatch/"/>
      <url>/2019/11/30/size-mismatch/</url>
      
        <content type="html"><![CDATA[<h3 id="今天跑代码遇到这个问题发现出错的位置是在卷积层到全连接层的地方卷积网络的每层节点个数都是事先定好的这对input的像素也有要求必须也是和预先设定的像素相同否则卷积层最后得出的结果会与设计的不同">今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。</h3><h3 id="卷积层结果一般是-batchsize-dimension0-1-1-全连接层只有二维-batchsize-dimensio_0会自动对之前四维的卷积结果进行压缩如果最后卷积结果不是-batchsize-dimension_0-1-1-的形式就不会被压缩成-batchsize-dimension_0-的形式而是别的形式下面就算不下去了">卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。</h3><p><br></p><p><img src="/images/size-mismatch/1.png"></p><p><br></p><h3 id="像下图这个网络参数对应的输入图像尺寸应该是-105-x-105-的但是我在预处理的时候没考虑到这点虽然事后可以debug出来但是应该事先要考虑到这点">像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。</h3><p><br></p><p><img src="/images/size-mismatch/3.png"></p>]]></content>
      
      
      <categories>
          
          <category> Thinking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python错误 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>将dataset标签写入txt</title>
      <link href="/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/"/>
      <url>/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/</url>
      
        <content type="html"><![CDATA[<h3 id="从网上获取的数据集想做成自己想要的样子要为该数据集做一个-label.txt-方便以后的训练比如像这样的第一列是图片位置第二列是标签">从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：</h3><p><br></p><p><img src="/images/将dataset标签写入txt/1.png"></p><p><br></p><h3 id="因为我原先的这个数据集里面每类样本数不一样所以稍微要烦一丢丢直接上代码">因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。</h3><p><br></p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a> </span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>roots <span class="op">=</span> <span class="st">"/home/yk/下载/VERI-Wild/images/"</span>             </span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert(train<span class="op">=</span><span class="va">True</span>):</span><span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train:</span><span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> <span class="bu">open</span>(roots <span class="op">+</span> <span class="st">'train.txt'</span>, <span class="st">'w'</span>)          <span class="co"># 新建了一个train.txt存label的信息</span></span><span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        data_path <span class="op">=</span> roots <span class="op">+</span> <span class="st">'images/'</span>           </span><span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_path):</span><span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>            os.makedirs(data_path)</span><span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="dv">0</span></span><span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> root, dirs, files <span class="kw">in</span> os.walk(data_path):</span><span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(dirs):</span><span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                <span class="co"># print(dirs)</span></span><span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span><span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span><span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> label <span class="op">+</span> <span class="dv">1</span></span><span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                s <span class="op">=</span> <span class="bu">len</span>(files)</span><span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(s):</span><span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                    img_path <span class="op">=</span> root <span class="op">+</span> <span class="st">'/'</span> <span class="op">+</span> files[i]</span><span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># print(img_path + ' ' + str(label))</span></span><span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                    f.write(img_path <span class="op">+</span> <span class="st">' '</span> <span class="op">+</span> <span class="bu">str</span>(label) <span class="op">+</span> <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)         <span class="co"># 写入文件</span></span><span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        f.close()</span><span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span><span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>convert(train<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>]]></content>
      
      
      <categories>
          
          <category> Practical Codes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>删除错误的更新源</title>
      <link href="/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/"/>
      <url>/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<h3 id="linux在执行-apt-get-update时有的时候会出现这样的情况">Linux在执行 apt-get update时，有的时候会出现这样的情况。</h3><h3 id="section"><br></h3><p><img src="/images/删除错误的更新源/1.png"></p><p><br></p><h3 id="之后每次对新的软件更新都会看到之前的错误提示很烦所以要把这些一直更新错误的软件信息删去如下图操作进入etcaptsources.list.d输入ls查看可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5">之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。</h3><p><br></p><p><img src="/images/删除错误的更新源/2.png"></p><p><br></p><h3 id="输入-sudo-rm-xxxxx文件名就可以删除该文件把相关的listsave文件一并删除">输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。</h3><p><br></p><p><img src="/images/删除错误的更新源/3.png"></p><p><br></p><h3 id="这时再-apt-get-update-时刚刚那个错误就消失了就这样把所有的之前更新不了的软件信息都删掉心旷神怡">这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！</h3><p><br></p><p><img src="/images/删除错误的更新源/6.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用Github+Hexo搭建Blog</title>
      <link href="/2019/11/24/first-time-record/"/>
      <url>/2019/11/24/first-time-record/</url>
      
        <content type="html"><![CDATA[<h3 id="happy.">Happy.</h3><p><img src="/images/c.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> Thinking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
