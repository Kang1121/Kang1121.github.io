<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kang&#39;s blog</title>
  
  <subtitle>��</subtitle>
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-05-24T02:10:29.109Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Kang Yin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DSNet: A Flexible Detect-to-Summarize Network for Video Summarization</title>
    <link href="http://yoursite.com/2021/05/24/DSNet/"/>
    <id>http://yoursite.com/2021/05/24/DSNet/</id>
    <published>2021-05-24T01:20:18.000Z</published>
    <updated>2021-05-24T02:10:29.109Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h3><p>&emsp;&emsp;&emsp;&emsp;代码：<a href="https://github.com/li-plus/DSNet" target="_blank" rel="noopener">https://github.com/li-plus/DSNet</a><br>&emsp;&emsp;&emsp;&emsp;兴趣程度 6</p><h3 id="1-Details"><a href="#1-Details" class="headerlink" title="1. Details"></a>1. Details</h3><p><img src="/images/DSNet/structure.png" alt></p><p><img src="/images/DSNet/2.jpg" alt></p><p><img src="/images/DSNet/3.jpg" alt></p><p><img src="/images/DSNet/6.jpg" alt></p><p><img src="/images/DSNet/7.jpg" alt></p><p><img src="/images/DSNet/8.jpg" alt></p><p><img src="/images/DSNet/9.jpg" alt></p><p><img src="/images/DSNet/10.jpg" alt></p><p><img src="/images/DSNet/11.jpg" alt></p><p><img src="/images/DSNet/12.jpg" alt></p><p><img src="/images/DSNet/13.jpg" alt></p><p><img src="/images/DSNet/14.jpg" alt></p><p><img src="/images/DSNet/15.jpg" alt></p><p><img src="/images/DSNet/16.jpg" alt></p><p><img src="/images/DSNet/17.jpg" alt></p><p><img src="/images/DSNet/18.jpg" alt></p><p><img src="/images/DSNet/19.jpg" alt></p><p><img src="/images/DSNet/20.jpg" alt></p><p><img src="/images/DSNet/21.jpg" alt></p><p><img src="/images/DSNet/22.jpg" alt></p><p><img src="/images/DSNet/23.jpg" alt></p><p><img src="/images/DSNet/24.jpg" alt></p><p><img src="/images/DSNet/25.jpg" alt></p><p><img src="/images/DSNet/26.jpg" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;&lt;a href=&quot;#0-Overview&quot; class=&quot;headerlink&quot; title=&quot;0. Overview&quot;&gt;&lt;/a&gt;0. Overview&lt;/h3&gt;&lt;p&gt;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;代码：&lt;a href=&quot;</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://yoursite.com/categories/Paper-Reading/"/>
    
    
    <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization</title>
    <link href="http://yoursite.com/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/"/>
    <id>http://yoursite.com/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/</id>
    <published>2021-04-20T07:44:40.000Z</published>
    <updated>2021-04-20T08:07:23.564Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h3><p><img src="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.png" alt></p><p>&emsp;&emsp;&emsp;&emsp;优点：frame-shot-video分层结构，双向LSTM滑动窗口<br>&emsp;&emsp;&emsp;&emsp;缺点：纯pixel features，supervised，importance score不新颖，滑动窗口k固定<br>&emsp;&emsp;&emsp;&emsp;兴趣程度：6</p><h3 id="1-Understanding"><a href="#1-Understanding" class="headerlink" title="1. Understanding"></a>1. Understanding</h3><p>&emsp;&emsp;&emsp;&emsp;中规中矩的一篇文章。提出了frame-shot-video的层级结构。先从frames中划分shots，再再划分的shots中，选择key shots。优点在于，单个shots的长度和shots的个数可变不固定，问题是默认了一个滑动窗口中必然出现shot boundary，这个是不一定的。选confidence score是用softmax的形式（n取1）。选shot boundary和key shot用的是一样的方法。</p><h3 id="2-Analysis"><a href="#2-Analysis" class="headerlink" title="2. Analysis"></a>2. Analysis</h3><p>&emsp;&emsp;&emsp;&emsp;由于这篇文章需要label，标记正确key shots的位置来训练，所以还有待改进。说到底，还是没有真正找到frames（shots）在高维空间中的联系（loss function），所以只能有监督。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;&lt;a href=&quot;#0-Overview&quot; class=&quot;headerlink&quot; title=&quot;0. Overview&quot;&gt;&lt;/a&gt;0. Overview&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2021/04/20/%C2%96HSA-RNN-</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://yoursite.com/categories/Paper-Reading/"/>
    
    
    <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Video Summarization via Relation-aware Assignment Learning</title>
    <link href="http://yoursite.com/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/"/>
    <id>http://yoursite.com/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/</id>
    <published>2021-04-19T01:58:07.000Z</published>
    <updated>2021-04-19T05:18:41.944Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h3><p><img src="/images/Unsupervised Video Summarization via Relation-aware Assignment Learning/2.png" alt></p><p>&emsp;&emsp;&emsp;&emsp;优点：使用GNN来表达relation，unsupervised<br>&emsp;&emsp;&emsp;&emsp;缺点：clip的划分，loss的选取，纯pixel提取<br>&emsp;&emsp;&emsp;&emsp;兴趣程度：7</p><h3 id="1-Understanding"><a href="#1-Understanding" class="headerlink" title="1. Understanding"></a>1. Understanding</h3><p>&emsp;&emsp;&emsp;&emsp;将一个视频分成等长的n个clips，e.g. 10000帧的视频分成等长的20个clips，每个clip包含500帧。每个clip feature作为GNN中的一个node。node之间的edge关系，不是用邻接矩阵表示，而且用全连接的网络得到。node之间传递信息的时候，也是用全连接，把edge的信息当作先验，更新node。<br>&emsp;&emsp;&emsp;&emsp;MLP是为了进一步提取feature，经过MLP后，得到n个更加representative的feature clips。用L2 norm得到它们的importance score（这边应该是通过node间的联系紧密程度来得到的），然后取前k个作为summary embedding其他为non-summary embedding。另外GNN中所有node合起来得到video embedding，这三个embedding一起放入loss。用了triplet loss，想拉近v和s，拉远v和n。</p><h3 id="2-Analysis"><a href="#2-Analysis" class="headerlink" title="2. Analysis"></a>2. Analysis</h3><p>&emsp;&emsp;&emsp;&emsp;可部分参考。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;&lt;a href=&quot;#0-Overview&quot; class=&quot;headerlink&quot; title=&quot;0. Overview&quot;&gt;&lt;/a&gt;0. Overview&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/Unsupervised Video</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://yoursite.com/categories/Paper-Reading/"/>
    
    
    <category term="GNN" scheme="http://yoursite.com/tags/GNN/"/>
    
    <category term="Video Summarization" scheme="http://yoursite.com/tags/Video-Summarization/"/>
    
  </entry>
  
  <entry>
    <title>Learning on Attribute-Missing Graphs</title>
    <link href="http://yoursite.com/2020/12/29/Learning-on-Attribute-Missing-Graphs/"/>
    <id>http://yoursite.com/2020/12/29/Learning-on-Attribute-Missing-Graphs/</id>
    <published>2020-12-28T15:19:02.000Z</published>
    <updated>2021-04-19T06:02:54.202Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Introduction"><a href="#0-Introduction" class="headerlink" title="0. Introduction"></a>0. Introduction</h3><p><img src="/images/Learning-on-Attribute-Missing-Graphs/structure.png" alt></p><p>&emsp;&emsp;Paper link: <a href="https://arxiv.org/pdf/2011.01623.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/2011.01623.pdf</a></p><p>&emsp;&emsp;Code link: <a href="https://github.com/xuChenSJTU/SAT-master-online" target="_blank" rel="noopener">https://github.com/xuChenSJTU/SAT-master-online</a></p><p>&emsp;&emsp;&emsp;&emsp;主要分析一下算法部分，实验部分不涉及。是VAE+GAN应用于graph的一个文章。用了两个VAE，分别训练X(attribute)和A(structure)。文章假设X和A的$z$在高维空间中遵从同一分布，然后用GAN对他们的高维分布$z$进行加强。</p><h3 id="1-VAE"><a href="#1-VAE" class="headerlink" title="1. VAE"></a>1. VAE</h3><p>&emsp;&emsp;&emsp;&emsp;普通的AE只要，求两个分布p和q使得：</p><script type="math/tex; mode=display">\hat x \approx q(z)\\z = p(x)</script><p>但是实际上操作，有很多局限性。VAE对$z$做限制，使其遵从某个分布，这样如果直接sample一个这个分布给他作为$q(x)$的输入，就可以得到一个相对纯AE来说不错的结果。$p$和$q$是两个NN。</p><p>&emsp;&emsp;&emsp;&emsp;VAE先推导一下。手上有一堆观测数据$x$，现在要求他们的分布$p(x)$。由于分布可能非常复杂，这里用GMM来表示。假设$x$由一个隐变量$z$控制。那么有</p><script type="math/tex; mode=display">p(x)=\int_z p(x|z)p(z)</script><p>接下来就是要求$p(x)$的MLE。即maximize</p><script type="math/tex; mode=display">L=\sum_x logp(x)</script><p>做个恒等变形，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}logp(x)&=\int_z q(z|x)log~p(x)dz=\int_z q(z|x)log\frac{p(x,z)}{p(z|x)}dz \\&=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz+\int_z q(z|x)log\frac{q(z|x)}{p(z|x)}dz \\&=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz +KL(q(z|x)||p(z|x))\\&\ge \int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz=\int_z q(z|x)log\frac{p(x|z)p(z)}{q(z|x)}dz=L_b\end{split}\nonumber\end{equation}</script><p>因而，就是要maximize$L_b$，而</p><script type="math/tex; mode=display">\begin{equation}\begin{split}L_b&=\int_z q(z|x)log\frac{p(z)}{q(z|x)}dz+\int_z q(z|x)logp(x|z)dz\\&=-KL(q(z|x)||p(z))+\int_z q(z|x)logp(x|z)dz\end{split}\nonumber\end{equation}</script><p>即minimize前者，maximize后者。前者只需训练 encoder $q$ 让他输出的分布 $z$ 接近 $p(z)$ 即可。后者可写成</p><script type="math/tex; mode=display">E_{x\sim q(z|x)}p(x|z)</script><p>即普通AE的工作。</p><h3 id="2-SAT"><a href="#2-SAT" class="headerlink" title="2. SAT"></a>2. SAT</h3><p>&emsp;&emsp;&emsp;&emsp;VAE+GAN的组合并不新鲜，但是这篇文章把它运用于重构图的节点信息，算是一个创新点。$X$表示的是每个node的attribute，$A$是整个图的structure。用两个VAE用于分别重构attribute和structure。其中，$E_x$、$D_x$、$D_A$是MLP，而$E_A$是GNN，其中的原因不是很懂。这篇文章是基于一个假设的，即：</p><blockquote><p>In graph structured data, each node’s attributes and structures are correlated together and can be represented in a shared-latent space.</p></blockquote><p>因为如果不这样，就不能让两个VAE通过隐变量$z$互相学习了。不过这个假设背后的数学原理（是否有），目前还不懂，但这个假设是非常关键的一步。所以$z$其实是一个桥梁，充当了两个角色，1）$E_x-&gt;z-&gt;D_A$和$E_A-&gt;z-&gt;D_x$；2）$z_A$和$z_X$的分布用GAN去拟合。所以这个VAE+GAN和之前有篇VAE-GAN本质上不一样，之前的是用GAN去强化$x$和$\hat x$，使单个VAE的表现更好，图像更清晰，而这篇文章是用GAN去使两个$z$遵从同一分布。</p><p>&emsp;&emsp;&emsp;&emsp;最后贴一下损失函数作为总结，首先是VAE部分的，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}min_{\theta_x,\theta_a,\phi_x,\phi_a}L_r =&− E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[logp_{\theta_x}(x_i|z_x)]]\\&− E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_a}(a_i|z_a)]]\\&− λ_c · E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_x}(x_i|z_a)]]\\&− λ_c · E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[log p_{\theta_a}(a_i|z_x)]]\end{split}\nonumber\end{equation}</script><p>其中，$\lambda_c$是调节上下两个的权重的。接下来是GAN的，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}min_\psi max_{\phi_x,\phi_a} L_{adv} = &− E_{z_p\sim p(z)}[log D(z_p)]\\&− E_{z_x\sim q_{\phi_x}(z_x|x_i)}[log(1 − D(z_x))]\\&− E_{z_p\sim p(z)}[log D(z_p)]\\&− E_{z_a\sim q_{\phi_a}(z_a|a_i)}[log(1 − D(z_a))]\end{split}\nonumber\end{equation}</script><p>其中，$\psi$是D的参数，$z_p$是label，来自某个分布，这里是Gaussian。最后是总的。</p><script type="math/tex; mode=display">min_\Theta max_\Phi L = L_r + L_{adv}</script><p>其中，$\Theta = {\theta_x, \theta_a, \phi_x, \phi_a, \psi}$ ，$ Φ = {\phi_x, \phi_a}$。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Introduction&quot;&gt;&lt;a href=&quot;#0-Introduction&quot; class=&quot;headerlink&quot; title=&quot;0. Introduction&quot;&gt;&lt;/a&gt;0. Introduction&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/Le</summary>
      
    
    
    
    <category term="Paper Reading" scheme="http://yoursite.com/categories/Paper-Reading/"/>
    
    
    <category term="GNN" scheme="http://yoursite.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>pip 镜像加速</title>
    <link href="http://yoursite.com/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/"/>
    <id>http://yoursite.com/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/</id>
    <published>2020-03-30T09:24:40.000Z</published>
    <updated>2021-04-19T05:55:08.565Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-1-emsp-临时指定源"><a href="#emsp-emsp-1-emsp-临时指定源" class="headerlink" title="&emsp;&emsp;1.&emsp;临时指定源"></a>&emsp;&emsp;1.&emsp;临时指定源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xxxxxxx 为安装对象</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple xxxxxxx</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-2-emsp-永久设定"><a href="#emsp-emsp-2-emsp-永久设定" class="headerlink" title="&emsp;&emsp;2.&emsp;永久设定"></a>&emsp;&emsp;2.&emsp;永久设定</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Linux   下创建或进入</span></span><br><span class="line"><span class="comment"># ~/.pip/pip.conf </span></span><br><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windows 下创建或进入</span></span><br><span class="line"><span class="comment"># C:/User/xxxxxxx/pip/pip.ini</span></span><br><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-1-emsp-临时指定源&quot;&gt;&lt;a href=&quot;#emsp-emsp-1-emsp-临时指定源&quot; class=&quot;headerlink&quot; title=&quot;&amp;emsp;&amp;emsp;1.&amp;emsp;临时指定源&quot;&gt;&lt;/a&gt;&amp;emsp;&amp;emsp;1.&amp;em</summary>
      
    
    
    
    <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
    <category term="下载加速" scheme="http://yoursite.com/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>终端加速</title>
    <link href="http://yoursite.com/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/"/>
    <id>http://yoursite.com/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/</id>
    <published>2020-03-30T09:05:29.000Z</published>
    <updated>2021-04-19T05:55:08.567Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Port number may vary </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Linux (electron_ssr)</span></span><br><span class="line"><span class="built_in">export</span> http_proxy=http://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> http_proxy=socks5://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> https_proxy=socks5://127.0.0.1:12333</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windows (cmd)(git)</span></span><br><span class="line"><span class="built_in">set</span> http_proxy=http://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> https_proxy=http://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> http_proxy=socks5://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> https_proxy=socks5://127.0.0.1:1080</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=</summary>
      
    
    
    
    <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
    <category term="下载加速" scheme="http://yoursite.com/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>LSF 作业调度系统</title>
    <link href="http://yoursite.com/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-03-24T01:50:44.000Z</published>
    <updated>2021-04-19T06:03:21.525Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-最近在搞-Vehicle-Re-Id-的时候，要跑的模型太大，有幸用到了某单位的超算。用的是-LSF-作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。"><a href="#emsp-emsp-最近在搞-Vehicle-Re-Id-的时候，要跑的模型太大，有幸用到了某单位的超算。用的是-LSF-作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。" class="headerlink" title="&emsp;&emsp;最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。"></a>&emsp;&emsp;最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。</h3><p>&lt;/br&gt;</p><h3 id="emsp-emsp-1-OS-amp-Software"><a href="#emsp-emsp-1-OS-amp-Software" class="headerlink" title="&emsp;&emsp;1. OS &amp; Software"></a>&emsp;&emsp;1. OS &amp; Software</h3><h3 id="emsp-emsp-emsp-emsp-Windows-10-Linux-下没有-GUI，用-FTP-传文件还是不方便，用-windows-的话就是直接文件交互比较方便"><a href="#emsp-emsp-emsp-emsp-Windows-10-Linux-下没有-GUI，用-FTP-传文件还是不方便，用-windows-的话就是直接文件交互比较方便" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;Windows 10 ( Linux 下没有 GUI，用 FTP 传文件还是不方便，用 windows 的话就是直接文件交互比较方便 )"></a>&emsp;&emsp;&emsp;&emsp;Windows 10 ( Linux 下没有 GUI，用 FTP 传文件还是不方便，用 windows 的话就是直接文件交互比较方便 )</h3><h3 id="emsp-emsp-emsp-emsp-软件用的是-MobaXterm。"><a href="#emsp-emsp-emsp-emsp-软件用的是-MobaXterm。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;软件用的是 MobaXterm。"></a>&emsp;&emsp;&emsp;&emsp;软件用的是 MobaXterm。</h3><p>&lt;/br&gt;</p><h3 id="emsp-emsp-2-Command-List"><a href="#emsp-emsp-2-Command-List" class="headerlink" title="&emsp;&emsp;2. Command List"></a>&emsp;&emsp;2. Command List</h3><h4 id="emsp-emsp-emsp-emsp-a-emsp-bsub-lt-lsf-sh"><a href="#emsp-emsp-emsp-emsp-a-emsp-bsub-lt-lsf-sh" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;a.&emsp;bsub &lt; lsf.sh"></a>&emsp;&emsp;&emsp;&emsp;a.&emsp;<strong>bsub &lt; lsf.sh</strong></h4><h4 id="emsp-emsp-emsp-emsp-其中，-lsf-sh-是自己写的一个脚本，之前犯错没输-lt-然后提交总是通不过。脚本范例如下："><a href="#emsp-emsp-emsp-emsp-其中，-lsf-sh-是自己写的一个脚本，之前犯错没输-lt-然后提交总是通不过。脚本范例如下：" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;其中， lsf.sh 是自己写的一个脚本，之前犯错没输 &lt;, 然后提交总是通不过。脚本范例如下："></a>&emsp;&emsp;&emsp;&emsp;其中， lsf.sh 是自己写的一个脚本，之前犯错没输 &lt;, 然后提交总是通不过。脚本范例如下：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/sh              </span></span><br><span class="line"><span class="comment">#BSUB -q gpu_v100 </span></span><br><span class="line"><span class="comment">#BSUB -m "gpu10"</span></span><br><span class="line"><span class="comment">#BSUB -gpu num=4:mode=exclusive_process</span></span><br><span class="line"><span class="comment">#BSUB -o %J.out</span></span><br><span class="line"><span class="comment">#BSUB -n 1</span></span><br><span class="line"><span class="comment">#BSUB -e %J.err</span></span><br><span class="line"><span class="comment">#BSUB -J Firsttry      </span></span><br><span class="line">python3 /xxx/xxx/xxx/xxx.py</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-b-emsp-bjobs"><a href="#emsp-emsp-emsp-emsp-b-emsp-bjobs" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;b.&emsp;bjobs"></a>&emsp;&emsp;&emsp;&emsp;b.&emsp;<strong>bjobs</strong></h4><h4 id="emsp-emsp-emsp-emsp-该指令可以查看当前正在运行的作业。"><a href="#emsp-emsp-emsp-emsp-该指令可以查看当前正在运行的作业。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;该指令可以查看当前正在运行的作业。"></a>&emsp;&emsp;&emsp;&emsp;该指令可以查看当前正在运行的作业。</h4><p><img src="/images/LSF作业调度系统/bjobs.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-emsp-emsp-bjobs-l-JOB-ID"><a href="#emsp-emsp-emsp-emsp-emsp-emsp-bjobs-l-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;bjobs -l JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>bjobs -l JOB_ID</strong></h4><h4 id="emsp-emsp-emsp-emsp-emsp-emsp-该指令可以查看当前正在运行的作业的详细情况。"><a href="#emsp-emsp-emsp-emsp-emsp-emsp-该指令可以查看当前正在运行的作业的详细情况。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;该指令可以查看当前正在运行的作业的详细情况。"></a>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;该指令可以查看当前正在运行的作业的详细情况。</h4><p><img src="/images/LSF作业调度系统/bjobs-l.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-emsp-emsp-bjobs-p-JOB-ID"><a href="#emsp-emsp-emsp-emsp-emsp-emsp-bjobs-p-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;bjobs -p JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>bjobs -p JOB_ID</strong></h4><h4 id="emsp-emsp-该指令可以查看作业-PENDING-的原因。"><a href="#emsp-emsp-该指令可以查看作业-PENDING-的原因。" class="headerlink" title="&emsp;&emsp;该指令可以查看作业 PENDING 的原因。"></a>&emsp;&emsp;该指令可以查看作业 PENDING 的原因。</h4><p><img src="/images/LSF作业调度系统/bjobs-p.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-c-emsp-bkill-JOB-ID"><a href="#emsp-emsp-emsp-emsp-c-emsp-bkill-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;c. &emsp;bkill JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;c. &emsp;<strong>bkill JOB_ID</strong></h4><h4 id="emsp-emsp-emsp-emsp-该指令可以结束作业。"><a href="#emsp-emsp-emsp-emsp-该指令可以结束作业。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;该指令可以结束作业。"></a>&emsp;&emsp;&emsp;&emsp;该指令可以结束作业。</h4><p><img src="/images/LSF作业调度系统/bkill.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-emsp-emsp-bkill-r-JOB-ID"><a href="#emsp-emsp-emsp-emsp-emsp-emsp-bkill-r-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;bkill -r JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>bkill -r JOB_ID</strong></h4><h4 id="emsp-emsp-emsp-emsp-由于刚接触-LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么-bkill-都结束不了作业，然后输入-info-bkill-查看了一下它的详细用法。这个可以直接杀死进程。"><a href="#emsp-emsp-emsp-emsp-由于刚接触-LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么-bkill-都结束不了作业，然后输入-info-bkill-查看了一下它的详细用法。这个可以直接杀死进程。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;由于刚接触 LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么 bkill 都结束不了作业，然后输入 info bkill 查看了一下它的详细用法。这个可以直接杀死进程。"></a>&emsp;&emsp;&emsp;&emsp;由于刚接触 LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么 bkill 都结束不了作业，然后输入 info bkill 查看了一下它的详细用法。这个可以直接杀死进程。</h4><p><img src="/images/LSF作业调度系统/bkill-r.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-d-emsp-bstop-JOB-ID-与-bresume-JOB-ID"><a href="#emsp-emsp-emsp-emsp-d-emsp-bstop-JOB-ID-与-bresume-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;d.&emsp;bstop JOB_ID 与 bresume JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;d.&emsp;<strong>bstop JOB_ID</strong> 与 <strong>bresume JOB_ID</strong></h4><h4 id="emsp-emsp-emsp-emsp-挂起和恢复作业，一般不用。如果作业不想继续了，最好直接-kill，否则占用资源。"><a href="#emsp-emsp-emsp-emsp-挂起和恢复作业，一般不用。如果作业不想继续了，最好直接-kill，否则占用资源。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;挂起和恢复作业，一般不用。如果作业不想继续了，最好直接 kill，否则占用资源。"></a>&emsp;&emsp;&emsp;&emsp;挂起和恢复作业，一般不用。如果作业不想继续了，最好直接 kill，否则占用资源。</h4><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-e-emsp-bpeek-JOB-ID-与-bpeek-f-JOB-ID"><a href="#emsp-emsp-emsp-emsp-e-emsp-bpeek-JOB-ID-与-bpeek-f-JOB-ID" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;e.&emsp;bpeek JOB_ID 与 bpeek -f JOB_ID"></a>&emsp;&emsp;&emsp;&emsp;e.&emsp;<strong>bpeek JOB_ID</strong> 与 <strong>bpeek -f JOB_ID</strong></h4><h4 id="emsp-emsp-emsp-emsp-该指令可以显示程序当前的屏幕输出。"><a href="#emsp-emsp-emsp-emsp-该指令可以显示程序当前的屏幕输出。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;该指令可以显示程序当前的屏幕输出。"></a>&emsp;&emsp;&emsp;&emsp;该指令可以显示程序当前的屏幕输出。</h4><p><img src="/images/LSF作业调度系统/bpeek.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-f-emsp-lsload-与-lsload-gpuload"><a href="#emsp-emsp-emsp-emsp-f-emsp-lsload-与-lsload-gpuload" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;f. &emsp;lsload 与 lsload -gpuload"></a>&emsp;&emsp;&emsp;&emsp;f. &emsp;<strong>lsload</strong> 与 <strong>lsload -gpuload</strong></h4><h4 id="emsp-emsp-emsp-emsp-该指令可以输出负载。"><a href="#emsp-emsp-emsp-emsp-该指令可以输出负载。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;该指令可以输出负载。"></a>&emsp;&emsp;&emsp;&emsp;该指令可以输出负载。</h4><p><img src="/images/LSF作业调度系统/lsload.jpg" alt></p><p>&lt;/br&gt;</p><h4 id="emsp-emsp-emsp-emsp-g-emsp-bhosts-与-bqueues"><a href="#emsp-emsp-emsp-emsp-g-emsp-bhosts-与-bqueues" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;g.&emsp;bhosts 与 bqueues"></a>&emsp;&emsp;&emsp;&emsp;g.&emsp;<strong>bhosts</strong> 与 <strong>bqueues</strong></h4><h4 id="emsp-emsp-emsp-emsp-该指令可以查看各个节点和队列的作业信息。"><a href="#emsp-emsp-emsp-emsp-该指令可以查看各个节点和队列的作业信息。" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;该指令可以查看各个节点和队列的作业信息。"></a>&emsp;&emsp;&emsp;&emsp;该指令可以查看各个节点和队列的作业信息。</h4><p><img src="/images/LSF作业调度系统/bhosts.jpg" alt></p><p><img src="/images/LSF作业调度系统/bqueues.jpg" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-3-Ending"><a href="#emsp-emsp-3-Ending" class="headerlink" title="&emsp;&emsp;3. Ending"></a>&emsp;&emsp;3. Ending</h3><h3 id="emsp-emsp-emsp-emsp-最后祝自己以后还有机会用这样的-GPU-集群。：）"><a href="#emsp-emsp-emsp-emsp-最后祝自己以后还有机会用这样的-GPU-集群。：）" class="headerlink" title="&emsp;&emsp;&emsp;&emsp;最后祝自己以后还有机会用这样的 GPU 集群。：）"></a>&emsp;&emsp;&emsp;&emsp;最后祝自己以后还有机会用这样的 GPU 集群。：）</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-最近在搞-Vehicle-Re-Id-的时候，要跑的模型太大，有幸用到了某单位的超算。用的是-LSF-作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。&quot;&gt;&lt;a href=&quot;#emsp-emsp-最近在搞-Vehicle-Re-Id-</summary>
      
    
    
    
    <category term="Thinking" scheme="http://yoursite.com/categories/Thinking/"/>
    
    
    <category term="LSF" scheme="http://yoursite.com/tags/LSF/"/>
    
  </entry>
  
  <entry>
    <title>GAN</title>
    <link href="http://yoursite.com/2020/02/17/GAN/"/>
    <id>http://yoursite.com/2020/02/17/GAN/</id>
    <published>2020-02-16T15:27:51.000Z</published>
    <updated>2021-04-19T06:03:38.054Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-0-Description"><a href="#emsp-0-Description" class="headerlink" title="&emsp;0. Description"></a>&emsp;0. Description</h3><h3 id="emsp-emsp-emsp-这篇-post-将所有了解过的-GAN-都写下来-方便回忆原理"><a href="#emsp-emsp-emsp-这篇-post-将所有了解过的-GAN-都写下来-方便回忆原理" class="headerlink" title="&emsp;&emsp;&emsp;这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理."></a>&emsp;&emsp;&emsp;这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理.</h3><p>&lt;/br&gt;</p><h3 id="emsp-1-GAN"><a href="#emsp-1-GAN" class="headerlink" title="&emsp;1. GAN"></a>&emsp;1. GAN</h3><h3 id="emsp-emsp-emsp-最初-GAN-的目的是想-generate-出和真实图片非常像的图片-有个有个图片集-data-假设它在某维空间满足某个分布"><a href="#emsp-emsp-emsp-最初-GAN-的目的是想-generate-出和真实图片非常像的图片-有个有个图片集-data-假设它在某维空间满足某个分布" class="headerlink" title="&emsp;&emsp;&emsp;最初 GAN 的目的是想 generate 出和真实图片非常像的图片. 有个有个图片集 data, 假设它在某维空间满足某个分布:"></a>&emsp;&emsp;&emsp;最初 GAN 的目的是想 generate 出和真实图片非常像的图片. 有个有个图片集 data, 假设它在某维空间满足某个分布:</h3><div align="center">     <img src="/images/GAN/1.png" width="50" height="35" align="center"></div><h3 id="emsp-emsp-emsp-但是现在不知道这个分布的-formula-现在可以做的是从这个-data-的分布中-sample-出一些图片-Generator-就希望能通过-network-学到一个分布"><a href="#emsp-emsp-emsp-但是现在不知道这个分布的-formula-现在可以做的是从这个-data-的分布中-sample-出一些图片-Generator-就希望能通过-network-学到一个分布" class="headerlink" title="&emsp;&emsp;&emsp;但是现在不知道这个分布的 formula, 现在可以做的是从这个 data 的分布中, sample 出一些图片. Generator 就希望能通过 network 学到一个分布:"></a>&emsp;&emsp;&emsp;但是现在不知道这个分布的 formula, 现在可以做的是从这个 data 的分布中, sample 出一些图片. Generator 就希望能通过 network 学到一个分布:</h3><div align="center">     <img src="/images/GAN/2.png" width="33" height="33" align="center"></div><h3 id="emsp-emsp-emsp-希望得到"><a href="#emsp-emsp-emsp-希望得到" class="headerlink" title="&emsp;&emsp;&emsp;希望得到:"></a>&emsp;&emsp;&emsp;希望得到:</h3><h3 id><a href="#" class="headerlink" title=" "></a> </h3><div align="center">     <img src="/images/GAN/3.png" width="110" height="38" align="center"></div><h3 id="emsp-emsp-emsp-也就是说-当这两个分布相等时-随便从-generator-学到的-distribution-中-sample-产生一个图片-都会是在-data-的distribution-中的-也就是说会是真实的图片"><a href="#emsp-emsp-emsp-也就是说-当这两个分布相等时-随便从-generator-学到的-distribution-中-sample-产生一个图片-都会是在-data-的distribution-中的-也就是说会是真实的图片" class="headerlink" title="&emsp;&emsp;&emsp;也就是说, 当这两个分布相等时, 随便从 generator 学到的 distribution 中 sample 产生一个图片, 都会是在 data 的distribution 中的, 也就是说会是真实的图片."></a>&emsp;&emsp;&emsp;也就是说, 当这两个分布相等时, 随便从 generator 学到的 distribution 中 sample 产生一个图片, 都会是在 data 的distribution 中的, 也就是说会是真实的图片.</h3><h3 id="emsp-emsp-emsp-因为-generator-是个-network-所以它要做的就是学到一个-network-使得这两个分布的-divergence-最小"><a href="#emsp-emsp-emsp-因为-generator-是个-network-所以它要做的就是学到一个-network-使得这两个分布的-divergence-最小" class="headerlink" title="&emsp;&emsp;&emsp;因为 generator 是个 network, 所以它要做的就是学到一个 network, 使得这两个分布的 divergence 最小:"></a>&emsp;&emsp;&emsp;因为 generator 是个 network, 所以它要做的就是学到一个 network, 使得这两个分布的 divergence 最小:</h3><div align="center">     <img src="/images/GAN/4.png" width="370" height="40" align="center"></div><h3 id="emsp-emsp-emsp-由于这两个分布它们的-formula-都不知道-所以-divergence-其实是不能直接算的-这个时候先把这个问题放一边-看一下-discriminator"><a href="#emsp-emsp-emsp-由于这两个分布它们的-formula-都不知道-所以-divergence-其实是不能直接算的-这个时候先把这个问题放一边-看一下-discriminator" class="headerlink" title="&emsp;&emsp;&emsp;由于这两个分布它们的 formula 都不知道, 所以 divergence 其实是不能直接算的. 这个时候先把这个问题放一边, 看一下 discriminator."></a>&emsp;&emsp;&emsp;由于这两个分布它们的 formula 都不知道, 所以 divergence 其实是不能直接算的. 这个时候先把这个问题放一边, 看一下 discriminator.</h3><p>&lt;/br&gt;</p><h3 id="emsp-emsp-emsp-Discriminator-要做的事情是区分真实的-image-和-generated-的-image-如果是从-data-distribution-中-sample-出来的-就给高分-如果是从-generated-distribution-中-sample-出来的-就给低分"><a href="#emsp-emsp-emsp-Discriminator-要做的事情是区分真实的-image-和-generated-的-image-如果是从-data-distribution-中-sample-出来的-就给高分-如果是从-generated-distribution-中-sample-出来的-就给低分" class="headerlink" title="&emsp;&emsp;&emsp; Discriminator 要做的事情是区分真实的 image 和 generated 的 image. 如果是从 data distribution 中 sample 出来的, 就给高分; 如果是从 generated distribution 中 sample 出来的, 就给低分:"></a>&emsp;&emsp;&emsp; Discriminator 要做的事情是区分真实的 image 和 generated 的 image. 如果是从 data distribution 中 sample 出来的, 就给高分; 如果是从 generated distribution 中 sample 出来的, 就给低分:</h3><div align="center">     <img src="/images/GAN/7.png" width="265" height="45" align="center"></div><h3 id="emsp-emsp-emsp-所以可以得到以下-cost-function-希望-V-越大越好-已经经过了一部分等价转换"><a href="#emsp-emsp-emsp-所以可以得到以下-cost-function-希望-V-越大越好-已经经过了一部分等价转换" class="headerlink" title="&emsp;&emsp;&emsp;所以可以得到以下 cost function, 希望 V 越大越好, 已经经过了一部分等价转换:"></a>&emsp;&emsp;&emsp;所以可以得到以下 cost function, 希望 V 越大越好, 已经经过了一部分等价转换:</h3><div align="center">     <img src="/images/GAN/5.png" width="570" height="40" align="center"></div><h3 id="emsp-emsp-emsp-把期望转成积分的形式"><a href="#emsp-emsp-emsp-把期望转成积分的形式" class="headerlink" title="&emsp;&emsp;&emsp;把期望转成积分的形式:"></a>&emsp;&emsp;&emsp;把期望转成积分的形式:</h3><div align="center">     <img src="/images/GAN/6.png" width="550" height="42" align="center"></div><h3 id="emsp-emsp-emsp-预期是-无论输入什么样的-x-只要来自于-generator-就给低分-只要来自于-real-sample-就给高分-所以其实-D-of-x-的在某处-e-g-x-0-的值不受任何附近-e-g-1-1-的值的影响-完全可以看成是一元函数求极值"><a href="#emsp-emsp-emsp-预期是-无论输入什么样的-x-只要来自于-generator-就给低分-只要来自于-real-sample-就给高分-所以其实-D-of-x-的在某处-e-g-x-0-的值不受任何附近-e-g-1-1-的值的影响-完全可以看成是一元函数求极值" class="headerlink" title="&emsp;&emsp;&emsp;预期是, 无论输入什么样的 x, 只要来自于 generator 就给低分, 只要来自于 real sample 就给高分, 所以其实 D of x 的在某处(e.g. x = 0)的值不受任何附近(e.g. (-1, 1))的值的影响, 完全可以看成是一元函数求极值."></a>&emsp;&emsp;&emsp;预期是, 无论输入什么样的 x, 只要来自于 generator 就给低分, 只要来自于 real sample 就给高分, 所以其实 D of x 的在某处(e.g. x = 0)的值不受任何附近(e.g. (-1, 1))的值的影响, 完全可以看成是一元函数求极值.</h3><div align="center">     <img src="/images/GAN/8.png" width="270" height="53" align="center"></div><h3 id="emsp-emsp-emsp-最后算出来-理论上-D-取这个值的时候-V-可以达到最大-也就是说-discriminator-的性能最好-但是两个分布都不知道-所以没有解析解-真正操作时这个用不了-但是把上式代入-V-中-整理后可得"><a href="#emsp-emsp-emsp-最后算出来-理论上-D-取这个值的时候-V-可以达到最大-也就是说-discriminator-的性能最好-但是两个分布都不知道-所以没有解析解-真正操作时这个用不了-但是把上式代入-V-中-整理后可得" class="headerlink" title="&emsp;&emsp;&emsp;最后算出来, 理论上 D 取这个值的时候 V 可以达到最大, 也就是说 discriminator 的性能最好. 但是两个分布都不知道, 所以没有解析解, 真正操作时这个用不了. 但是把上式代入 V 中, 整理后可得:"></a>&emsp;&emsp;&emsp;最后算出来, 理论上 D 取这个值的时候 V 可以达到最大, 也就是说 discriminator 的性能最好. 但是两个分布都不知道, 所以没有解析解, 真正操作时这个用不了. 但是把上式代入 V 中, 整理后可得:</h3><div align="center">     <img src="/images/GAN/9.png" width="600" height="50" align="center"></div><h3 id="emsp-emsp-emsp-发现这个正好是-JS-divergence-的形式-又由于最初要求的就是-g-和-data-distribution-的-divergence-所以把上式代入-G-star-得"><a href="#emsp-emsp-emsp-发现这个正好是-JS-divergence-的形式-又由于最初要求的就是-g-和-data-distribution-的-divergence-所以把上式代入-G-star-得" class="headerlink" title="&emsp;&emsp;&emsp;发现这个正好是 JS divergence 的形式. 又由于最初要求的就是 g 和 data distribution 的 divergence, 所以把上式代入 G star 得:"></a>&emsp;&emsp;&emsp;发现这个正好是 JS divergence 的形式. 又由于最初要求的就是 g 和 data distribution 的 divergence, 所以把上式代入 G star 得:</h3><div align="center">     <img src="/images/GAN/10.png" width="320" height="52" align="center"></div><h3 id="emsp-emsp-emsp-这个式子就可以用-network-求了-先固定-Generator-训练-Discriminator-让-V-达到-max-再固定-Discriminator-训练-Generator-使得-V-取最小值-Iteratively-训练"><a href="#emsp-emsp-emsp-这个式子就可以用-network-求了-先固定-Generator-训练-Discriminator-让-V-达到-max-再固定-Discriminator-训练-Generator-使得-V-取最小值-Iteratively-训练" class="headerlink" title="&emsp;&emsp;&emsp;这个式子就可以用 network 求了. 先固定 Generator 训练 Discriminator 让 V 达到 max, 再固定 Discriminator  训练 Generator 使得 V 取最小值. Iteratively 训练."></a>&emsp;&emsp;&emsp;这个式子就可以用 network 求了. 先固定 Generator 训练 Discriminator 让 V 达到 max, 再固定 Discriminator  训练 Generator 使得 V 取最小值. Iteratively 训练.</h3><p>&lt;/br&gt;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">"images"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--n_epochs"</span>, type=int, default=<span class="number">200</span>, help=<span class="string">"number of epochs of training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--batch_size"</span>, type=int, default=<span class="number">64</span>, help=<span class="string">"size of the batches"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lr"</span>, type=float, default=<span class="number">0.0002</span>, help=<span class="string">"adam: learning rate"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b1"</span>, type=float, default=<span class="number">0.5</span>, help=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--b2"</span>, type=float, default=<span class="number">0.999</span>, help=<span class="string">"adam: decay of first order momentum of gradient"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--n_cpu"</span>, type=int, default=<span class="number">8</span>, help=<span class="string">"number of cpu threads to use during batch generation"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--latent_dim"</span>, type=int, default=<span class="number">100</span>, help=<span class="string">"dimensionality of the latent space"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--img_size"</span>, type=int, default=<span class="number">28</span>, help=<span class="string">"size of each image dimension"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--channels"</span>, type=int, default=<span class="number">1</span>, help=<span class="string">"number of image channels"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--sample_interval"</span>, type=int, default=<span class="number">400</span>, help=<span class="string">"interval betwen image samples"</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line">print(opt)</span><br><span class="line"></span><br><span class="line">img_shape = (opt.channels, opt.img_size, opt.img_size)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">block</span><span class="params">(in_feat, out_feat, normalize=True)</span>:</span></span><br><span class="line">            layers = [nn.Linear(in_feat, out_feat)]</span><br><span class="line">            <span class="keyword">if</span> normalize:</span><br><span class="line">                layers.append(nn.BatchNorm1d(out_feat, <span class="number">0.8</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            *block(opt.latent_dim, <span class="number">128</span>, normalize=<span class="literal">False</span>),</span><br><span class="line">            *block(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            *block(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            *block(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, int(np.prod(img_shape))),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, z)</span>:</span></span><br><span class="line">        img = self.model(z)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), *img_shape)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(int(np.prod(img_shape)), <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, img)</span>:</span></span><br><span class="line">        img_flat = img.view(img.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        validity = self.model(img_flat)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> validity</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss function</span></span><br><span class="line">adversarial_loss = torch.nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize generator and discriminator</span></span><br><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> cuda:</span><br><span class="line">    generator.cuda()</span><br><span class="line">    discriminator.cuda()</span><br><span class="line">    adversarial_loss.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure data loader</span></span><br><span class="line">os.makedirs(<span class="string">"../../data/mnist"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(</span><br><span class="line">        <span class="string">"../../data/mnist"</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transforms.Compose(</span><br><span class="line">            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    batch_size=opt.batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizers</span></span><br><span class="line">optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line">optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br><span class="line"></span><br><span class="line">Tensor = torch.cuda.FloatTensor <span class="keyword">if</span> cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"><span class="comment">#  Training</span></span><br><span class="line"><span class="comment"># ----------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(opt.n_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (imgs, _) <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Adversarial ground truths</span></span><br><span class="line">        valid = Variable(Tensor(imgs.size(<span class="number">0</span>), <span class="number">1</span>).fill_(<span class="number">1.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line">        fake = Variable(Tensor(imgs.size(<span class="number">0</span>), <span class="number">1</span>).fill_(<span class="number">0.0</span>), requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Configure input</span></span><br><span class="line">        real_imgs = Variable(imgs.type(Tensor))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line">        <span class="comment">#  Train Generator</span></span><br><span class="line">        <span class="comment"># -----------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_G.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sample noise as generator input</span></span><br><span class="line">        z = Variable(Tensor(np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (imgs.shape[<span class="number">0</span>], opt.latent_dim))))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a batch of images</span></span><br><span class="line">        gen_imgs = generator(z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loss measures generator's ability to fool the discriminator</span></span><br><span class="line">        g_loss = adversarial_loss(discriminator(gen_imgs), valid)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        optimizer_G.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment">#  Train Discriminator</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line"></span><br><span class="line">        optimizer_D.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Measure discriminator's ability to classify real from generated samples</span></span><br><span class="line">        real_loss = adversarial_loss(discriminator(real_imgs), valid)</span><br><span class="line">        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)</span><br><span class="line">        d_loss = (real_loss + fake_loss) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        optimizer_D.step()</span><br><span class="line"></span><br><span class="line">        print(</span><br><span class="line">            <span class="string">"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"</span></span><br><span class="line">            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        batches_done = epoch * len(dataloader) + i</span><br><span class="line">        <span class="keyword">if</span> batches_done % opt.sample_interval == <span class="number">0</span>:</span><br><span class="line">            save_image(gen_imgs.data[:<span class="number">25</span>], <span class="string">"images/%d.png"</span> % batches_done, nrow=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-0-Description&quot;&gt;&lt;a href=&quot;#emsp-0-Description&quot; class=&quot;headerlink&quot; title=&quot;&amp;emsp;0. Description&quot;&gt;&lt;/a&gt;&amp;emsp;0. Description&lt;/h3&gt;&lt;h3 i</summary>
      
    
    
    
    <category term="Theoretical Analysis" scheme="http://yoursite.com/categories/Theoretical-Analysis/"/>
    
    
  </entry>
  
  <entry>
    <title>sorted 对 class 元素排序</title>
    <link href="http://yoursite.com/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/"/>
    <id>http://yoursite.com/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/</id>
    <published>2020-02-12T10:56:02.000Z</published>
    <updated>2021-04-19T06:04:24.499Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">unit</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, label)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.label = label</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">a = [unit(<span class="literal">None</span>, <span class="literal">None</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对a赋值后</span></span><br><span class="line"><span class="comment"># reverse = True 降序, 默认为 False 升序</span></span><br><span class="line">a = sorted(a, key=<span class="keyword">lambda</span> student: student.value, reverse = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="emsp-emsp-student-可随便换其他名字"><a href="#emsp-emsp-student-可随便换其他名字" class="headerlink" title="&emsp;&emsp;student 可随便换其他名字"></a>&emsp;&emsp;student 可随便换其他名字</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Example&quot;&gt;&lt;a href=&quot;#Example&quot; class=&quot;headerlink&quot; title=&quot;Example&quot;&gt;&lt;/a&gt;Example&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class</summary>
      
    
    
    
    <category term="Practical Codes" scheme="http://yoursite.com/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>mAP CMC</title>
    <link href="http://yoursite.com/2020/02/12/mAP-CMC/"/>
    <id>http://yoursite.com/2020/02/12/mAP-CMC/</id>
    <published>2020-02-12T10:53:29.000Z</published>
    <updated>2021-04-19T06:04:37.040Z</updated>
    
    <content type="html"><![CDATA[<h2 id="mAP-Mean-Average-Precision"><a href="#mAP-Mean-Average-Precision" class="headerlink" title="mAP(Mean Average Precision)"></a>mAP<strong>(Mean Average Precision)</strong></h2><h3 id="emsp-emsp-0-TP-amp-FN-amp-TN-amp-FP"><a href="#emsp-emsp-0-TP-amp-FN-amp-TN-amp-FP" class="headerlink" title="&emsp;&emsp;0.    TP &amp; FN &amp; TN &amp; FP"></a>&emsp;&emsp;0.    TP &amp; FN &amp; TN &amp; FP</h3><h4 id="emsp-emsp-emsp-TP-是-true-positive-表示正样本被判断为正样本-即T-true-FN-是-false-negative-表示-negative-sample-被判断为-positive-sample-即F-false-另外两个也一样"><a href="#emsp-emsp-emsp-TP-是-true-positive-表示正样本被判断为正样本-即T-true-FN-是-false-negative-表示-negative-sample-被判断为-positive-sample-即F-false-另外两个也一样" class="headerlink" title="&emsp;&emsp;&emsp;TP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样."></a>&emsp;&emsp;&emsp;TP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样.</h4><h3 id="emsp-emsp-1-Precision-amp-Recall"><a href="#emsp-emsp-1-Precision-amp-Recall" class="headerlink" title="&emsp;&emsp;1.    Precision &amp; Recall"></a>&emsp;&emsp;1.    Precision &amp; Recall</h3><h4 id="emsp-emsp-emsp-分类问题中-现在已有每个样本的概率值和标签-0-1-将样本按照概率从高到底排序-分类器表现理想的情况是-标签为-1-的样本都在上面-标签为-0-的样本都在下面-有个-threshold-一开始指向最上面的-sample-然后每次下移一个-threshold-及以上的都被认为是-positive-sample-下面的都被认为是-negative-sample"><a href="#emsp-emsp-emsp-分类问题中-现在已有每个样本的概率值和标签-0-1-将样本按照概率从高到底排序-分类器表现理想的情况是-标签为-1-的样本都在上面-标签为-0-的样本都在下面-有个-threshold-一开始指向最上面的-sample-然后每次下移一个-threshold-及以上的都被认为是-positive-sample-下面的都被认为是-negative-sample" class="headerlink" title="&emsp;&emsp;&emsp;分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及以上的都被认为是 positive sample, 下面的都被认为是 negative sample."></a>&emsp;&emsp;&emsp;分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及以上的都被认为是 positive sample, 下面的都被认为是 negative sample.</h4><h4 id="emsp-emsp-emsp-Precision-TP-TP-FN-假设-TP-FN-k-precision-就表示前-k-个样本中-“negative-sample-的比例”-因为它们本来应该呆在-positive-sample-下面的-但它们现在跑到-positive-sample-上面去了-有几个-positive-sample-就计算几个-precision-threshold-每次下移一个-当移到某个-sample-为-positive-sample-的时候再算-precision"><a href="#emsp-emsp-emsp-Precision-TP-TP-FN-假设-TP-FN-k-precision-就表示前-k-个样本中-“negative-sample-的比例”-因为它们本来应该呆在-positive-sample-下面的-但它们现在跑到-positive-sample-上面去了-有几个-positive-sample-就计算几个-precision-threshold-每次下移一个-当移到某个-sample-为-positive-sample-的时候再算-precision" class="headerlink" title="&emsp;&emsp;&emsp;Precision = TP / (TP + FN)    假设 TP + FN = k, precision 就表示前 k 个样本中, “negative sample 的比例”, 因为它们本来应该呆在 positive sample 下面的, 但它们现在跑到 positive sample 上面去了. 有几个 positive sample 就计算几个 precision, threshold 每次下移一个, 当移到某个 sample 为 positive sample 的时候再算 precision."></a>&emsp;&emsp;&emsp;Precision = TP / (TP + FN)    假设 TP + FN = k, precision 就表示前 k 个样本中, “negative sample 的比例”, 因为它们本来应该呆在 positive sample 下面的, 但它们现在跑到 positive sample 上面去了. 有几个 positive sample 就计算几个 precision, threshold 每次下移一个, 当移到某个 sample 为 positive sample 的时候再算 precision.</h4><h4 id="emsp-emsp-emsp-Recall-TP-TP-FP-表示-positive-sample-被成功找回来的概率-因为-positive-sample-总数不变-所以-TP-FP-不变-Recall-最终会为1"><a href="#emsp-emsp-emsp-Recall-TP-TP-FP-表示-positive-sample-被成功找回来的概率-因为-positive-sample-总数不变-所以-TP-FP-不变-Recall-最终会为1" class="headerlink" title="&emsp;&emsp;&emsp;Recall = TP / (TP + FP)     表示 positive sample 被成功找回来的概率. 因为 positive sample 总数不变, 所以 TP + FP 不变. Recall 最终会为1."></a>&emsp;&emsp;&emsp;Recall = TP / (TP + FP)     表示 positive sample 被成功找回来的概率. 因为 positive sample 总数不变, 所以 TP + FP 不变. Recall 最终会为1.</h4><h3 id="emsp-emsp-2-AP-amp-mAP"><a href="#emsp-emsp-2-AP-amp-mAP" class="headerlink" title="&emsp;&emsp;2.    AP &amp; mAP"></a>&emsp;&emsp;2.    AP &amp; mAP</h3><h4 id="emsp-emsp-emsp-假设有"><a href="#emsp-emsp-emsp-假设有" class="headerlink" title="&emsp;&emsp;&emsp;假设有"></a>&emsp;&emsp;&emsp;假设有</h4><script type="math/tex; mode=display">AP =\frac{\sum^N_1 precision}{N}</script><p>&lt;/br&gt;</p><h2 id="CMC-Cumulative-Match-Characteristics"><a href="#CMC-Cumulative-Match-Characteristics" class="headerlink" title="CMC(Cumulative Match Characteristics)"></a>CMC<strong>(Cumulative Match Characteristics)</strong></h2><h3 id="emsp-emsp"><a href="#emsp-emsp" class="headerlink" title="&emsp;&emsp;"></a>&emsp;&emsp;</h3><p>&lt;/br&gt;</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;mAP-Mean-Average-Precision&quot;&gt;&lt;a href=&quot;#mAP-Mean-Average-Precision&quot; class=&quot;headerlink&quot; title=&quot;mAP(Mean Average Precision)&quot;&gt;&lt;/a&gt;mAP&lt;str</summary>
      
    
    
    
    <category term="Metrics" scheme="http://yoursite.com/categories/Metrics/"/>
    
    
  </entry>
  
  <entry>
    <title>Image.convert转化图片</title>
    <link href="http://yoursite.com/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/"/>
    <id>http://yoursite.com/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/</id>
    <published>2019-12-20T11:19:34.000Z</published>
    <updated>2021-04-19T06:04:44.735Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1 ------------------（1位像素，黑白，每字节一个像素存储）</span><br><span class="line">L ------------------（8位像素，黑白）</span><br><span class="line">P ------------------（8位像素，使用调色板映射到任何其他模式）</span><br><span class="line">RGB-------------- （3x8位像素，真彩色）</span><br><span class="line">RGBA-------------（4x8位像素，带透明度掩模的真彩色）</span><br><span class="line">CMYK-------------（4x8位像素，分色）</span><br><span class="line">YCbCr------------ （3x8位像素，彩色视频格式）</span><br><span class="line">I--------------------（32位有符号整数像素）</span><br><span class="line">F------------------- （32位浮点像素）</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'1'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/a.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'L'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/b.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'P'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/c.png" width="320" height="240" align="center"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; Image.open(path).convert(&#39;RGB&#39;)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/d.png" width="320" height="240" align="center"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; Image.open(path).convert(&#39;RGBA&#39;)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/e.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'CMYK'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/f.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'YCbCr'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/g.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'I'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/h.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'F'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/k.png" width="320" height="240" align="center"></div>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class</summary>
      
    
    
    
    <category term="Practical Codes" scheme="http://yoursite.com/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>模型的保存与载入</title>
    <link href="http://yoursite.com/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/"/>
    <id>http://yoursite.com/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/</id>
    <published>2019-12-19T10:02:48.000Z</published>
    <updated>2021-04-19T06:04:53.053Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。"><a href="#emsp-emsp-跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。" class="headerlink" title="&emsp;&emsp;跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。"></a>&emsp;&emsp;跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。</h3><p>&lt;/br&gt;</p><h3 id="emsp-emsp-保存："><a href="#emsp-emsp-保存：" class="headerlink" title="&emsp;&emsp;保存："></a>&emsp;&emsp;保存：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(net.state_dict(), model_path + <span class="string">'/model-inter-'</span> + str(batch_id+<span class="number">1</span>) + <span class="string">".pt"</span>)</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错："><a href="#emsp-emsp-加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错：" class="headerlink" title="&emsp;&emsp;加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错："></a>&emsp;&emsp;加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = Siamese()</span><br><span class="line">net.load_state_dict(torch.load(<span class="string">'/home/yk/siamese-pytorch/models/model-inter-104001.pt'</span>, map_location=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pyto</summary>
      
    
    
    
    <category term="Practical Codes" scheme="http://yoursite.com/categories/Practical-Codes/"/>
    
    
    <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>制作自己的 dataset</title>
    <link href="http://yoursite.com/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/"/>
    <id>http://yoursite.com/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/</id>
    <published>2019-12-01T10:34:03.000Z</published>
    <updated>2021-04-19T06:04:49.061Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。"><a href="#emsp-emsp-制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。" class="headerlink" title="&emsp;&emsp;制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader  封装就好了。"></a>&emsp;&emsp;制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader  封装就好了。</h3><hr><h1 id="一、Dataset-制作"><a href="#一、Dataset-制作" class="headerlink" title="一、Dataset 制作"></a>一、Dataset 制作</h1><h3 id="emsp-emsp-一般-Dataset-类有以下的函数："><a href="#emsp-emsp-一般-Dataset-类有以下的函数：" class="headerlink" title="&emsp;&emsp;一般 Dataset 类有以下的函数："></a>&emsp;&emsp;一般 Dataset 类有以下的函数：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ...)</span>:</span></span><br><span class="line">...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-init-是初始化时传入的一些参数，不是非常重要。"><a href="#emsp-emsp-init-是初始化时传入的一些参数，不是非常重要。" class="headerlink" title="&emsp;&emsp;__init__() 是初始化时传入的一些参数，不是非常重要。"></a>&emsp;&emsp;__init__() 是初始化时传入的一些参数，不是非常重要。</h3><h3 id="emsp-emsp-getitem-需要自己修改，功能是将图片从磁盘中读入，存入-array-或者-list-中。"><a href="#emsp-emsp-getitem-需要自己修改，功能是将图片从磁盘中读入，存入-array-或者-list-中。" class="headerlink" title="&emsp;&emsp;__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。"></a>&emsp;&emsp;__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。</h3><h3 id="emsp-emsp-len-是返回-Dataset-的大小，需要仔细设计。"><a href="#emsp-emsp-len-是返回-Dataset-的大小，需要仔细设计。" class="headerlink" title="&emsp;&emsp;__len()__ 是返回 Dataset 的大小，需要仔细设计。"></a>&emsp;&emsp;__len()__ 是返回 Dataset 的大小，需要仔细设计。</h3><h3 id="emsp-emsp-下面是两个用于构建Siamese-Nerual-Network-的-example-。"><a href="#emsp-emsp-下面是两个用于构建Siamese-Nerual-Network-的-example-。" class="headerlink" title="&emsp;&emsp;下面是两个用于构建Siamese Nerual Network 的 example 。"></a>&emsp;&emsp;下面是两个用于构建Siamese Nerual Network 的 example 。</h3><h3 id="emsp-emsp-这个是事先将图片的-path-都写入了一个-txt-文件中，然后-getitem-就从-txt-中读图片路径。"><a href="#emsp-emsp-这个是事先将图片的-path-都写入了一个-txt-文件中，然后-getitem-就从-txt-中读图片路径。" class="headerlink" title="&emsp;&emsp;这个是事先将图片的 path 都写入了一个 txt 文件中，然后 getitem 就从 txt 中读图片路径。"></a>&emsp;&emsp;这个是事先将图片的 path 都写入了一个 txt 文件中，然后 getitem 就从 txt 中读图片路径。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, txt, transform=None, target_transform=None, should_invert=False)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.target_transform = target_transform</span><br><span class="line">        self.should_invert = should_invert</span><br><span class="line">        self.txt = txt</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line"></span><br><span class="line">        line = linecache.getline(self.txt, random.randint(<span class="number">1</span>, self.__len__()))</span><br><span class="line">        line.strip(<span class="string">'\n'</span>)</span><br><span class="line">        img0_list = line.split()</span><br><span class="line">        <span class="comment"># 判断是否要选同一个类别的图片</span></span><br><span class="line">        should_get_same_class = random.randint(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> should_get_same_class:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># 随机在 txt 中选一行读取，每一行有一张图片的 path 和它的 label</span></span><br><span class="line">                img1_list = linecache.getline(self.txt, random.randint(<span class="number">1</span>, self.__len__())).strip(<span class="string">'\n'</span>).split()</span><br><span class="line">                <span class="keyword">if</span> img0_list[<span class="number">1</span>] == img1_list[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            img1_list = linecache.getline(self.txt, random.randint(<span class="number">1</span>, self.__len__())).strip(<span class="string">'\n'</span>).split()</span><br><span class="line"></span><br><span class="line">        img0 = Image.open(img0_list[<span class="number">0</span>])</span><br><span class="line">        img1 = Image.open(img1_list[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># 转图片通道数</span></span><br><span class="line">        img0 = img0.convert(<span class="string">"L"</span>)</span><br><span class="line">        img1 = img1.convert(<span class="string">"L"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 非必要的</span></span><br><span class="line">        <span class="keyword">if</span> self.should_invert:</span><br><span class="line">            img0 = PIL.ImageOps.invert(img0)</span><br><span class="line">            img1 = PIL.ImageOps.invert(img1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 非必要的</span></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img0 = self.transform(img0)</span><br><span class="line">            img1 = self.transform(img1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img0, img1, torch.from_numpy(np.array([int(img1_list[<span class="number">1</span>] != img0_list[<span class="number">1</span>])], dtype=np.float32))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这个 len 的返回长度就是 txt 中图片总数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        fh = open(self.txt, <span class="string">'r'</span>)</span><br><span class="line">        num = len(fh.readlines())</span><br><span class="line">        fh.close()</span><br><span class="line">        <span class="keyword">return</span> num</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-这个是事先没有准备-txt-目录，所以写了一个-loadToMem-去每个文件夹里面找图片。"><a href="#emsp-emsp-这个是事先没有准备-txt-目录，所以写了一个-loadToMem-去每个文件夹里面找图片。" class="headerlink" title="&emsp;&emsp;这个是事先没有准备 txt 目录，所以写了一个 loadToMem 去每个文件夹里面找图片。"></a>&emsp;&emsp;这个是事先没有准备 txt 目录，所以写了一个 loadToMem 去每个文件夹里面找图片。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OmniglotTest</span><span class="params">(Dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataPath, transform=None, times=<span class="number">100</span>, way=<span class="number">166</span>)</span>:</span></span><br><span class="line">        np.random.seed(<span class="number">1</span>)</span><br><span class="line">        super(OmniglotTest, self).__init__()</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.times = times</span><br><span class="line">        self.way = way</span><br><span class="line">        self.img1 = <span class="literal">None</span></span><br><span class="line">        self.c1 = <span class="literal">None</span></span><br><span class="line">        self.datas, self.num_classes = self.loadToMem(dataPath)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadToMem</span><span class="params">(self, dataPath)</span>:</span></span><br><span class="line">        print(<span class="string">"begin loading test dataset to memory"</span>)</span><br><span class="line">        <span class="comment"># datas 是读取到的图片的总 list，idx 是类别数。</span></span><br><span class="line">        datas = &#123;&#125;</span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> alphaPath <span class="keyword">in</span> os.listdir(dataPath):</span><br><span class="line">            <span class="comment"># for charPath in os.listdir(os.path.join(dataPath, alphaPath)):</span></span><br><span class="line">                datas[idx] = []</span><br><span class="line">                <span class="keyword">for</span> samplePath <span class="keyword">in</span> os.listdir(os.path.join(dataPath, alphaPath)):</span><br><span class="line">                    filePath = os.path.join(dataPath, alphaPath, samplePath)</span><br><span class="line">                    s = Image.open(filePath).convert(<span class="string">'L'</span>)</span><br><span class="line">                    <span class="comment"># 调整图片尺寸</span></span><br><span class="line">                    s = s.resize((<span class="number">105</span>, <span class="number">105</span>), Image.ANTIALIAS)</span><br><span class="line">                    datas[idx].append(s)</span><br><span class="line">                idx += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"finish loading test dataset to memory"</span>)</span><br><span class="line">        <span class="keyword">return</span> datas, idx</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.times * self.way</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        idx = index % self.way</span><br><span class="line">        label = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># generate image pair from same class</span></span><br><span class="line">        <span class="keyword">if</span> idx == <span class="number">0</span>:</span><br><span class="line">            self.c1 = random.randint(<span class="number">0</span>, self.num_classes - <span class="number">1</span>)</span><br><span class="line">            self.img1 = random.choice(self.datas[self.c1])</span><br><span class="line">            img2 = random.choice(self.datas[self.c1])</span><br><span class="line">        <span class="comment"># generate image pair from different class</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c2 = random.randint(<span class="number">0</span>, self.num_classes - <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">while</span> self.c1 == c2:</span><br><span class="line">                c2 = random.randint(<span class="number">0</span>, self.num_classes - <span class="number">1</span>)</span><br><span class="line">            img2 = random.choice(self.datas[c2])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            img1 = self.transform(self.img1)</span><br><span class="line">            img2 = self.transform(img2)</span><br><span class="line">        <span class="comment"># print('datas.shape = ', len(self.datas))</span></span><br><span class="line">        <span class="comment"># print('img1 = ', img1.shape)</span></span><br><span class="line">        <span class="comment"># print('img2 = ', img2.shape)</span></span><br><span class="line">        <span class="keyword">return</span> img1, img2</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><hr><h1 id="二、Dataloader-封装"><a href="#二、Dataloader-封装" class="headerlink" title="二、Dataloader 封装"></a>二、Dataloader 封装</h1><h3 id="emsp-emsp-这个比较简单，因为-Dataloader-是-Pytorch-内置的函数。"><a href="#emsp-emsp-这个比较简单，因为-Dataloader-是-Pytorch-内置的函数。" class="headerlink" title="&emsp;&emsp;这个比较简单，因为 Dataloader 是 Pytorch 内置的函数。"></a>&emsp;&emsp;这个比较简单，因为 Dataloader 是 Pytorch 内置的函数。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataloader = DataLoader(dataset=train_data, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, batch_size=Config.train_batch_size)</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-主要需要关注的是-batch-size-。这个以及之前提到的-len-和训练的次数有关。"><a href="#emsp-emsp-主要需要关注的是-batch-size-。这个以及之前提到的-len-和训练的次数有关。" class="headerlink" title="&emsp;&emsp;主要需要关注的是 batch_size 。这个以及之前提到的 len 和训练的次数有关。"></a>&emsp;&emsp;主要需要关注的是 batch_size 。这个以及之前提到的 len 和训练的次数有关。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(train_dataloader, <span class="number">0</span>):</span><br></pre></td></tr></table></figure><p>&lt;/br&gt;</p><h3 id="emsp-emsp-其中，for-循环的次数-len-batch-size-。"><a href="#emsp-emsp-其中，for-循环的次数-len-batch-size-。" class="headerlink" title="&emsp;&emsp;其中，for 循环的次数 = len / batch_size 。"></a>&emsp;&emsp;其中，for 循环的次数 = len / batch_size 。</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。&quot;&gt;&lt;a href=&quot;#emsp-emsp-制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-</summary>
      
    
    
    
    <category term="Practical Codes" scheme="http://yoursite.com/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>RuntimeError: size mismatch, m1: [128 x 184320], m2: [9216 x 4096]</title>
    <link href="http://yoursite.com/2019/11/30/size-mismatch/"/>
    <id>http://yoursite.com/2019/11/30/size-mismatch/</id>
    <published>2019-11-30T07:42:55.000Z</published>
    <updated>2021-04-19T06:03:17.668Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。"><a href="#emsp-emsp-今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。" class="headerlink" title="&emsp;&emsp;今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。"></a>&emsp;&emsp;今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。</h3><h3 id="emsp-emsp-卷积层结果一般是-batchsize-dimension0-1-1-，-全连接层只有二维-batchsize-dimensio-0-，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是-batchsize-dimension-0-1-1-的形式，就不会被压缩成-batchsize-dimension-0-的形式，而是别的形式。下面就算不下去了。"><a href="#emsp-emsp-卷积层结果一般是-batchsize-dimension0-1-1-，-全连接层只有二维-batchsize-dimensio-0-，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是-batchsize-dimension-0-1-1-的形式，就不会被压缩成-batchsize-dimension-0-的形式，而是别的形式。下面就算不下去了。" class="headerlink" title="&emsp;&emsp;卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。"></a>&emsp;&emsp;卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。</h3><p>&lt;/br&gt;</p><p><img src="/images/size-mismatch/1.png" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-像下图这个网络参数对应的输入图像尺寸应该是-105-x-105-的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。"><a href="#emsp-emsp-像下图这个网络参数对应的输入图像尺寸应该是-105-x-105-的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。" class="headerlink" title="&emsp;&emsp;像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。"></a>&emsp;&emsp;像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。</h3><p>&lt;/br&gt;</p><p><img src="/images/size-mismatch/3.png" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。&quot;&gt;&lt;a href=&quot;#emsp-ems</summary>
      
    
    
    
    <category term="Thinking" scheme="http://yoursite.com/categories/Thinking/"/>
    
    
    <category term="Python 错误" scheme="http://yoursite.com/tags/Python-%E9%94%99%E8%AF%AF/"/>
    
  </entry>
  
  <entry>
    <title>将dataset标签写入txt</title>
    <link href="http://yoursite.com/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/"/>
    <id>http://yoursite.com/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/</id>
    <published>2019-11-26T10:26:15.000Z</published>
    <updated>2021-04-19T06:04:18.839Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签："><a href="#emsp-emsp-从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：" class="headerlink" title="&emsp;&emsp;从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签："></a>&emsp;&emsp;从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：</h3><p>&lt;/br&gt;</p><p><img src="/images/将dataset标签写入txt/1.png" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。"><a href="#emsp-emsp-因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。" class="headerlink" title="&emsp;&emsp;因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。"></a>&emsp;&emsp;因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。</h3><p>&lt;/br&gt;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"> </span><br><span class="line">roots = <span class="string">"/home/yk/下载/VERI-Wild/images/"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(train=True)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        f = open(roots + <span class="string">'train.txt'</span>, <span class="string">'w'</span>)<span class="comment"># 新建了一个train.txt存label的信息</span></span><br><span class="line">        data_path = roots + <span class="string">'images/'</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(data_path):</span><br><span class="line">            os.makedirs(data_path)</span><br><span class="line">        label = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(data_path):</span><br><span class="line">            <span class="keyword">if</span> len(dirs):</span><br><span class="line">                <span class="comment"># print(dirs)</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                label = label + <span class="number">1</span></span><br><span class="line">                s = len(files)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(s):</span><br><span class="line">                    img_path = root + <span class="string">'/'</span> + files[i]</span><br><span class="line">                    <span class="comment"># print(img_path + ' ' + str(label))</span></span><br><span class="line">                    f.write(img_path + <span class="string">' '</span> + str(label) + <span class="string">'\n'</span>)<span class="comment"># 写入文件</span></span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">convert(train=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：&quot;&gt;&lt;a href=&quot;#emsp-emsp-从网上获取的数据集，想做成自己想要的样子，要为该数据集做</summary>
      
    
    
    
    <category term="Practical Codes" scheme="http://yoursite.com/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>删除错误的更新源</title>
    <link href="http://yoursite.com/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/"/>
    <id>http://yoursite.com/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/</id>
    <published>2019-11-26T09:44:59.000Z</published>
    <updated>2021-04-19T05:55:08.566Z</updated>
    
    <content type="html"><![CDATA[<h3 id="emsp-emsp-Linux在执行-apt-get-update时，有的时候会出现这样的情况。"><a href="#emsp-emsp-Linux在执行-apt-get-update时，有的时候会出现这样的情况。" class="headerlink" title="&emsp;&emsp;Linux在执行 apt-get update时，有的时候会出现这样的情况。"></a>&emsp;&emsp;Linux在执行 apt-get update时，有的时候会出现这样的情况。</h3><h3 id="lt-br-gt"><a href="#lt-br-gt" class="headerlink" title="&lt;/br&gt;"></a>&lt;/br&gt;</h3><p><img src="/images/删除错误的更新源/1.png" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入-etc-apt-sources-list-d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。"><a href="#emsp-emsp-之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入-etc-apt-sources-list-d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。" class="headerlink" title="&emsp;&emsp;之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。"></a>&emsp;&emsp;之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/2.png" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-输入-sudo-rm-XXXXX-文件名-，就可以删除该文件，把相关的list、save文件一并删除。"><a href="#emsp-emsp-输入-sudo-rm-XXXXX-文件名-，就可以删除该文件，把相关的list、save文件一并删除。" class="headerlink" title="&emsp;&emsp;输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。"></a>&emsp;&emsp;输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/3.png" alt></p><p>&lt;/br&gt;</p><h3 id="emsp-emsp-这时再-apt-get-update-时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！"><a href="#emsp-emsp-这时再-apt-get-update-时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！" class="headerlink" title="&emsp;&emsp;这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！"></a>&emsp;&emsp;这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/6.png" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;emsp-emsp-Linux在执行-apt-get-update时，有的时候会出现这样的情况。&quot;&gt;&lt;a href=&quot;#emsp-emsp-Linux在执行-apt-get-update时，有的时候会出现这样的情况。&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>使用Github+Hexo搭建Blog</title>
    <link href="http://yoursite.com/2019/11/24/first-time-record/"/>
    <id>http://yoursite.com/2019/11/24/first-time-record/</id>
    <published>2019-11-24T10:25:46.000Z</published>
    <updated>2021-04-19T06:03:49.220Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Happy"><a href="#Happy" class="headerlink" title="Happy."></a>Happy.</h3><p><img src="/images/c.jpg" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Happy&quot;&gt;&lt;a href=&quot;#Happy&quot; class=&quot;headerlink&quot; title=&quot;Happy.&quot;&gt;&lt;/a&gt;Happy.&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/c.jpg&quot; alt&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Thinking" scheme="http://yoursite.com/categories/Thinking/"/>
    
    
    <category term="Life" scheme="http://yoursite.com/tags/Life/"/>
    
  </entry>
  
</feed>
