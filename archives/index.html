<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Kang Yin's blog</title><meta name="description" content="My blog"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Kang's blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Kang Yin's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>Archives · All</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/">Brain-Controlled Robotic Arm System Based on Multi-Directional CNN-BiLSTMNetwork Using EEG Signals</a></h2><time class="has-text-grey" datetime="2021-06-30T04:25:02.000Z">2021-06-30</time><p class="is-flex-grow-2 mt-2"></p><a class="button is-default mt-2 has-text-weight-semibold" href="/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/DSNet/2.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2021/05/24/DSNet/"><img class="post-cover-img js-img-fadeIn" src="/images/DSNet/2.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LSTM"><i class="tag post-item-tag">LSTM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2021/05/24/DSNet/">DSNet: A Flexible Detect-to-Summarize Network for Video Summarization</a></h2><time class="has-text-grey" datetime="2021-05-24T01:20:18.000Z">2021-05-24</time><p class="is-flex-grow-2 mt-2">0. Overview    代码：https://github.com/li-plus/DSNet    兴趣程度 6
1. Details






















</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2021/05/24/DSNet/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/"><img class="post-cover-img js-img-fadeIn" src="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LSTM"><i class="tag post-item-tag">LSTM</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/">HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization</a></h2><time class="has-text-grey" datetime="2021-04-20T07:44:40.000Z">2021-04-20</time><p class="is-flex-grow-2 mt-2">0. Overview

优点：frame-shot-video分层结构，双向LSTM滑动窗口
缺点：纯pixel features，supervised，importance score不新颖，滑动窗口k固定
兴趣程度：6
1. Understanding
中规中矩的一篇文章。提出了frame-shot-video的层级结构。先从frames中划分shots，再再划分的shots中，选择key shots。优点在于，单个shots的长度和shots的个数可变不固定，问题是默认了一个滑动窗口中必然出现shot boundary，这个是不一定的。选confidence score是用softmax的形式（n取1）。选shot boundary和key shot用的是一样的方法。
2. Analysis
由于这..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/GNN"><i class="tag post-item-tag">GNN</i></a><a href="/tags/VideoSummarization"><i class="tag post-item-tag">VideoSummarization</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/">Unsupervised Video Summarization via Relation-aware Assignment Learning</a></h2><time class="has-text-grey" datetime="2021-04-19T01:58:07.000Z">2021-04-19</time><p class="is-flex-grow-2 mt-2">0. Overview
优点：使用GNN来表达relation，unsupervised缺点：clip的划分，loss的选取，纯pixel提取兴趣程度：7
1. Understanding将一个视频分成等长的n个clips，e.g. 10000帧的视频分成等长的20个clips，每个clip包含500帧。每个clip feature作为GNN中的一个node。node之间的edge关系，不是用邻接矩阵表示，而且用全连接的网络得到。node之间传递信息的时候，也是用全连接，把edge的信息当作先验，更新node。MLP是为了进一步提取feature，经过MLP后，得到n个更加representative的feature clips。用L2 norm得到它们的importance score（这边应该是通过no..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/Learning-on-Attribute-Missing-Graphs/structure.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2020/12/29/Learning-on-Attribute-Missing-Graphs/"><img class="post-cover-img js-img-fadeIn" src="/images/Learning-on-Attribute-Missing-Graphs/structure.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/GNN"><i class="tag post-item-tag">GNN</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/12/29/Learning-on-Attribute-Missing-Graphs/">Learning on Attribute-Missing Graphs</a></h2><time class="has-text-grey" datetime="2020-12-28T15:19:02.000Z">2020-12-29</time><p class="is-flex-grow-2 mt-2">0. Introduction
Paper link: https://arxiv.org/pdf/2011.01623.pdf
Code link: https://github.com/xuChenSJTU/SAT-master-online
主要分析一下算法部分，实验部分不涉及。是VAE+GAN应用于graph的一个文章。用了两个VAE，分别训练X(attribute)和A(structure)。文章假设X和A的$z$在高维空间中遵从同一分布，然后用GAN对他们的高维分布$z$进行加强。
1. VAE普通的AE只要，求两个分布p和q使得：

\hat x \approx q(z)\\
z = p(x)但是实际上操作，有很多局限性。VAE对$z$做限制，使其遵从某个分布，这样如果直接sample一个这个..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/12/29/Learning-on-Attribute-Missing-Graphs/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F"><i class="tag post-item-tag">下载加速</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/">pip 镜像加速</a></h2><time class="has-text-grey" datetime="2020-03-30T09:24:40.000Z">2020-03-30</time><p class="is-flex-grow-2 mt-2">1.临时指定源# xxxxxxx 为安装对象
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple xxxxxxx

&amp;lt;/br&amp;gt;
2.永久设定 # Linux   下创建或进入
 # ~/.pip/pip.conf 
 [global]
 index-url = https://pypi.tuna.tsinghua.edu.cn/simple

 # Windows 下创建或进入
 # C:/User/xxxxxxx/pip/pip.ini
 [global]
 index-url = https://pypi.tuna.tsinghua.edu.cn/simple

</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F"><i class="tag post-item-tag">下载加速</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/">终端加速</a></h2><time class="has-text-grey" datetime="2020-03-30T09:05:29.000Z">2020-03-30</time><p class="is-flex-grow-2 mt-2">12345678910111213# Port number may vary # Linux (electron_ssr)export http_proxy=http://127.0.0.1:12333export https_proxy=http://127.0.0.1:12333export http_proxy=socks5://127.0.0.1:12333export https_proxy=socks5://127.0.0.1:12333# Windows (cmd)(git)set http_proxy=http://127.0.0.1:1080set https_proxy=http://127.0.0.1:1080set http_proxy=socks5://127.0.0.1:108..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bjobs.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"><img class="post-cover-img js-img-fadeIn" src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bjobs.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/LSF"><i class="tag post-item-tag">LSF</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/">LSF 作业调度系统</a></h2><time class="has-text-grey" datetime="2020-03-24T01:50:44.000Z">2020-03-24</time><p class="is-flex-grow-2 mt-2">0. Intro
最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。
1. OS &amp;amp; Software
Windows 10 ( Linux 下没有 GUI，用 FTP 传文件还是不方便，用 windows 的话就是直接文件交互比较方便 )
软件用的是 MobaXterm。
2. Command List
bsub &amp;lt; lsf.sh
其中， lsf.sh 是自己写的一个脚本，之前犯错没输 &amp;lt;, 然后提交总是通不过。脚本范例如下：
# !/bin/sh
# BSUB -q gpu_v100
# BSUB -m &quot;gpu10&quot;
# BSUB -gpu num=4:mode=excl..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/GAN/1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2020/02/17/GAN/"><img class="post-cover-img js-img-fadeIn" src="/images/GAN/1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/02/17/GAN/">GAN</a></h2><time class="has-text-grey" datetime="2020-02-16T15:27:51.000Z">2020-02-17</time><p class="is-flex-grow-2 mt-2">0. Description
这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理.
1. GAN
最初 GAN 的目的是想 generate 出和真实图片非常像的图片. 有个有个图片集 data, 假设它在某维空间满足某个分布:
    
 

但是现在不知道这个分布的 formula, 现在可以做的是从这个 data 的分布中, sample 出一些图片. Generator 就希望能通过 network 学到一个分布:
    
 

希望得到:
    
 

也就是说, 当这两个分布相等时, 随便从 generator 学到的 distribution 中 sample 产生一个图片, 都会是在 data 的distribution 中的, 也就是说会是真实的图片.
因为 genera..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/02/17/GAN/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/">sorted 对 class 元素排序</a></h2><time class="has-text-grey" datetime="2020-02-12T10:56:02.000Z">2020-02-12</time><p class="is-flex-grow-2 mt-2">Exampleclass unit(object):
    def __init__(self, value, label):
        self.value = value
        self.label = label


a = [unit(None, None) for i in range(1000)]

# 对a赋值后
# reverse = True 降序, 默认为 False 升序
a = sorted(a, key=lambda student: student.value, reverse = True)

student 可随便换其他名字</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2020/02/12/mAP-CMC/">mAP CMC</a></h2><time class="has-text-grey" datetime="2020-02-12T10:53:29.000Z">2020-02-12</time><p class="is-flex-grow-2 mt-2">mAP(Mean Average Precision)0.    TP &amp;amp; FN &amp;amp; TN &amp;amp; FPTP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样.1.    Precision &amp;amp; Recall分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2020/02/12/mAP-CMC/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/Image.convert转化图片/a.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/"><img class="post-cover-img js-img-fadeIn" src="/images/Image.convert转化图片/a.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/">Image.convert转化图片</a></h2><time class="has-text-grey" datetime="2019-12-20T11:19:34.000Z">2019-12-20</time><p class="is-flex-grow-2 mt-2">1234567891 ------------------（1位像素，黑白，每字节一个像素存储）L ------------------（8位像素，黑白）P ------------------（8位像素，使用调色板映射到任何其他模式）RGB-------------- （3x8位像素，真彩色）RGBA-------------（4x8位像素，带透明度掩模的真彩色）CMYK-------------（4x8位像素，分色）YCbCr------------ （3x8位像素，彩色视频格式）I--------------------（32位有符号整数像素）F------------------- （32位浮点像素）
1img = Image.open(path).convert('1')
    
 




1..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Pytorch"><i class="tag post-item-tag">Pytorch</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/">模型的保存与载入</a></h2><time class="has-text-grey" datetime="2019-12-19T10:02:48.000Z">2019-12-19</time><p class="is-flex-grow-2 mt-2">跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。&amp;lt;/br&amp;gt;
保存：torch.save(net.state_dict(), model_path + '/model-inter-' + str(batch_id+1) + &quot;.pt&quot;)

&amp;lt;/br&amp;gt;
加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：net = Siamese()
net.load_state_dict(torch.load('/home/yk/siam..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/">Read more</a></section></article><article class="post-item-card"><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/">制作自己的 dataset</a></h2><time class="has-text-grey" datetime="2019-12-01T10:34:03.000Z">2019-12-01</time><p class="is-flex-grow-2 mt-2">制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader  封装就好了。
一、Dataset 制作一般 Dataset 类有以下的函数：class Dataset(Dataset):

    def __init__(self, ...):
        ...
    def __getitem__(self, index):
        ...
    def __len__(self):
        ...

&amp;lt;/br&amp;gt;
__init__() 是初始化时传入的一些参数，不是非常重要。__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。__len()__ 是返回 Dataset 的大小，需要..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/size-mismatch/1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2019/11/30/size-mismatch/"><img class="post-cover-img js-img-fadeIn" src="/images/size-mismatch/1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Python%E9%94%99%E8%AF%AF"><i class="tag post-item-tag">Python错误</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/11/30/size-mismatch/">RuntimeError: size mismatch, m1: [128 x 184320], m2: [9216 x 4096]</a></h2><time class="has-text-grey" datetime="2019-11-30T07:42:55.000Z">2019-11-30</time><p class="is-flex-grow-2 mt-2">今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。&amp;lt;/br&amp;gt;

&amp;lt;/br&amp;gt;
像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/11/30/size-mismatch/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/将dataset标签写入txt/1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/"><img class="post-cover-img js-img-fadeIn" src="/images/将dataset标签写入txt/1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/">将dataset标签写入txt</a></h2><time class="has-text-grey" datetime="2019-11-26T10:26:15.000Z">2019-11-26</time><p class="is-flex-grow-2 mt-2">从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：&amp;lt;/br&amp;gt;

&amp;lt;/br&amp;gt;
因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。&amp;lt;/br&amp;gt;
import os

roots = &quot;/home/yk/下载/VERI-Wild/images/&quot;                


def convert(train=True):
    if train:
        f = open(roots + 'train.txt', 'w')            # 新建了一个train.txt存label的信息
        data_path = roo..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/删除错误的更新源/1.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/"><img class="post-cover-img js-img-fadeIn" src="/images/删除错误的更新源/1.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/">删除错误的更新源</a></h2><time class="has-text-grey" datetime="2019-11-26T09:44:59.000Z">2019-11-26</time><p class="is-flex-grow-2 mt-2">Linux在执行 apt-get update时，有的时候会出现这样的情况。&amp;lt;/br&amp;gt;
&amp;lt;/br&amp;gt;
之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。&amp;lt;/br&amp;gt;

&amp;lt;/br&amp;gt;
输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。&amp;lt;/br&amp;gt;

&amp;lt;/br&amp;gt;
这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！&amp;lt;/br&amp;gt;

</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/c.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2019/11/24/first-time-record/"><img class="post-cover-img js-img-fadeIn" src="/images/c.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Life"><i class="tag post-item-tag">Life</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2019/11/24/first-time-record/">使用Github+Hexo搭建Blog</a></h2><time class="has-text-grey" datetime="2019-11-24T10:25:46.000Z">2019-11-24</time><p class="is-flex-grow-2 mt-2">Happy.
</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2019/11/24/first-time-record/">Read more</a></section></article></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">4</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/kang1121"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/kang.97kk/?hl=zh-cn"><i class="iconfont icon-ins"></i></a><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/康-殷-33665b15a"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--></section><p><span>Copyright ©</span><span> Kang Yin 2021</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>