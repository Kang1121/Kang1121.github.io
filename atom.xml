<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kang&#39;s blog</title>
  
  <subtitle>��</subtitle>
  <link href="https://kang1121.github.io/atom.xml" rel="self"/>
  
  <link href="https://kang1121.github.io/"/>
  <updated>2021-06-30T04:25:49.803Z</updated>
  <id>https://kang1121.github.io/</id>
  
  <author>
    <name>Kang Yin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Brain-Controlled Robotic Arm System Based on Multi-Directional CNN-BiLSTMNetwork Using EEG Signals</title>
    <link href="https://kang1121.github.io/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/"/>
    <id>https://kang1121.github.io/2021/06/30/Brain-Controlled-Robotic-Arm-System-Based-on-Multi-Directional-CNN-BiLSTM-Network-Using-EEG-Signals/</id>
    <published>2021-06-30T04:25:02.000Z</published>
    <updated>2021-06-30T04:25:49.803Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>DSNet: A Flexible Detect-to-Summarize Network for Video Summarization</title>
    <link href="https://kang1121.github.io/2021/05/24/DSNet/"/>
    <id>https://kang1121.github.io/2021/05/24/DSNet/</id>
    <published>2021-05-24T01:20:18.000Z</published>
    <updated>2021-06-30T05:29:00.719Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h3><p>    代码：<a href="https://github.com/li-plus/DSNet">https://github.com/li-plus/DSNet</a><br>    兴趣程度 6</p><h3 id="1-Details"><a href="#1-Details" class="headerlink" title="1. Details"></a>1. Details</h3><p><img src="/images/DSNet/2.png" alt=""></p><p><img src="/images/DSNet/3.png" alt=""></p><p><img src="/images/DSNet/6.png" alt=""></p><p><img src="/images/DSNet/7.png" alt=""></p><p><img src="/images/DSNet/8.png" alt=""></p><p><img src="/images/DSNet/9.png" alt=""></p><p><img src="/images/DSNet/10.png" alt=""></p><p><img src="/images/DSNet/11.png" alt=""></p><p><img src="/images/DSNet/12.png" alt=""></p><p><img src="/images/DSNet/13.png" alt=""></p><p><img src="/images/DSNet/14.png" alt=""></p><p><img src="/images/DSNet/15.png" alt=""></p><p><img src="/images/DSNet/16.png" alt=""></p><p><img src="/images/DSNet/17.png" alt=""></p><p><img src="/images/DSNet/18.png" alt=""></p><p><img src="/images/DSNet/19.png" alt=""></p><p><img src="/images/DSNet/20.png" alt=""></p><p><img src="/images/DSNet/21.png" alt=""></p><p><img src="/images/DSNet/22.png" alt=""></p><p><img src="/images/DSNet/23.png" alt=""></p><p><img src="/images/DSNet/24.png" alt=""></p><p><img src="/images/DSNet/25.png" alt=""></p><p><img src="/images/DSNet/26.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;&lt;a href=&quot;#0-Overview&quot; class=&quot;headerlink&quot; title=&quot;0. Overview&quot;&gt;&lt;/a&gt;0. Overview&lt;/h3&gt;&lt;p&gt;    代码：&lt;a href=&quot;https://github.com/l</summary>
      
    
    
    
    <category term="Paper Reading" scheme="https://kang1121.github.io/categories/Paper-Reading/"/>
    
    
    <category term="LSTM" scheme="https://kang1121.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization</title>
    <link href="https://kang1121.github.io/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/"/>
    <id>https://kang1121.github.io/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/</id>
    <published>2021-04-20T07:44:40.000Z</published>
    <updated>2021-06-30T06:02:27.238Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview">0. Overview</h3><p><img src="/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.png" alt=""></p><p>优点：frame-shot-video分层结构，双向LSTM滑动窗口<br>缺点：纯pixel features，supervised，importance score不新颖，滑动窗口k固定<br>兴趣程度：6</p><h3 id="1-Understanding">1. Understanding</h3><p>中规中矩的一篇文章。提出了frame-shot-video的层级结构。先从frames中划分shots，再再划分的shots中，选择key shots。优点在于，单个shots的长度和shots的个数可变不固定，问题是默认了一个滑动窗口中必然出现shot boundary，这个是不一定的。选confidence score是用softmax的形式（n取1）。选shot boundary和key shot用的是一样的方法。</p><h3 id="2-Analysis">2. Analysis</h3><p>由于这篇文章需要label，标记正确key shots的位置来训练，所以还有待改进。说到底，还是没有真正找到frames（shots）在高维空间中的联系（loss function），所以只能有监督。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;0. Overview&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/2021/04/20/%C2%96HSA-RNN-Hierarchical-Structure-Adaptive-RNN-for-Video-Summarization/1.pn</summary>
      
    
    
    
    <category term="Paper Reading" scheme="https://kang1121.github.io/categories/Paper-Reading/"/>
    
    
    <category term="LSTM" scheme="https://kang1121.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Video Summarization via Relation-aware Assignment Learning</title>
    <link href="https://kang1121.github.io/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/"/>
    <id>https://kang1121.github.io/2021/04/19/Unsupervised%20Video%20Summarization%20via%20Relation-aware%20Assignment%20Learning/</id>
    <published>2021-04-19T01:58:07.000Z</published>
    <updated>2021-06-30T05:40:46.327Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h3><p><img src="/images/Unsupervised Video Summarization via Relation-aware Assignment Learning/2.png" alt=""></p><p>优点：使用GNN来表达relation，unsupervised<br>缺点：clip的划分，loss的选取，纯pixel提取<br>兴趣程度：7</p><h3 id="1-Understanding"><a href="#1-Understanding" class="headerlink" title="1. Understanding"></a>1. Understanding</h3><p>将一个视频分成等长的n个clips，e.g. 10000帧的视频分成等长的20个clips，每个clip包含500帧。每个clip feature作为GNN中的一个node。node之间的edge关系，不是用邻接矩阵表示，而且用全连接的网络得到。node之间传递信息的时候，也是用全连接，把edge的信息当作先验，更新node。<br>MLP是为了进一步提取feature，经过MLP后，得到n个更加representative的feature clips。用L2 norm得到它们的importance score（这边应该是通过node间的联系紧密程度来得到的），然后取前k个作为summary embedding其他为non-summary embedding。另外GNN中所有node合起来得到video embedding，这三个embedding一起放入loss。用了triplet loss，想拉近v和s，拉远v和n。</p><h3 id="2-Analysis"><a href="#2-Analysis" class="headerlink" title="2. Analysis"></a>2. Analysis</h3><p>可部分参考。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Overview&quot;&gt;&lt;a href=&quot;#0-Overview&quot; class=&quot;headerlink&quot; title=&quot;0. Overview&quot;&gt;&lt;/a&gt;0. Overview&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/Unsupervised Video</summary>
      
    
    
    
    <category term="Paper Reading" scheme="https://kang1121.github.io/categories/Paper-Reading/"/>
    
    
    <category term="GNN" scheme="https://kang1121.github.io/tags/GNN/"/>
    
    <category term="VideoSummarization" scheme="https://kang1121.github.io/tags/VideoSummarization/"/>
    
  </entry>
  
  <entry>
    <title>Learning on Attribute-Missing Graphs</title>
    <link href="https://kang1121.github.io/2020/12/29/Learning-on-Attribute-Missing-Graphs/"/>
    <id>https://kang1121.github.io/2020/12/29/Learning-on-Attribute-Missing-Graphs/</id>
    <published>2020-12-28T15:19:02.000Z</published>
    <updated>2021-06-30T05:37:25.995Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Introduction"><a href="#0-Introduction" class="headerlink" title="0. Introduction"></a>0. Introduction</h3><p><img src="/images/Learning-on-Attribute-Missing-Graphs/structure.png" alt=""></p><p>Paper link: <a href="https://arxiv.org/pdf/2011.01623.pdf">https://arxiv.org/pdf/2011.01623.pdf</a></p><p>Code link: <a href="https://github.com/xuChenSJTU/SAT-master-online">https://github.com/xuChenSJTU/SAT-master-online</a></p><p>主要分析一下算法部分，实验部分不涉及。是VAE+GAN应用于graph的一个文章。用了两个VAE，分别训练X(attribute)和A(structure)。文章假设X和A的$z$在高维空间中遵从同一分布，然后用GAN对他们的高维分布$z$进行加强。</p><h3 id="1-VAE"><a href="#1-VAE" class="headerlink" title="1. VAE"></a>1. VAE</h3><p>普通的AE只要，求两个分布p和q使得：</p><script type="math/tex; mode=display">\hat x \approx q(z)\\z = p(x)</script><p>但是实际上操作，有很多局限性。VAE对$z$做限制，使其遵从某个分布，这样如果直接sample一个这个分布给他作为$q(x)$的输入，就可以得到一个相对纯AE来说不错的结果。$p$和$q$是两个NN。</p><p>VAE先推导一下。手上有一堆观测数据$x$，现在要求他们的分布$p(x)$。由于分布可能非常复杂，这里用GMM来表示。假设$x$由一个隐变量$z$控制。那么有</p><script type="math/tex; mode=display">p(x)=\int_z p(x|z)p(z)</script><p>接下来就是要求$p(x)$的MLE。即maximize</p><script type="math/tex; mode=display">L=\sum_x logp(x)</script><p>做个恒等变形，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}logp(x)&=\int_z q(z|x)log~p(x)dz=\int_z q(z|x)log\frac{p(x,z)}{p(z|x)}dz \\&=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz+\int_z q(z|x)log\frac{q(z|x)}{p(z|x)}dz \\&=\int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz +KL(q(z|x)||p(z|x))\\&\ge \int_z q(z|x)log\frac{p(x,z)}{q(z|x)}dz=\int_z q(z|x)log\frac{p(x|z)p(z)}{q(z|x)}dz=L_b\end{split}\nonumber\end{equation}</script><p>因而，就是要maximize$L_b$，而</p><script type="math/tex; mode=display">\begin{equation}\begin{split}L_b&=\int_z q(z|x)log\frac{p(z)}{q(z|x)}dz+\int_z q(z|x)logp(x|z)dz\\&=-KL(q(z|x)||p(z))+\int_z q(z|x)logp(x|z)dz\end{split}\nonumber\end{equation}</script><p>即minimize前者，maximize后者。前者只需训练 encoder $q$ 让他输出的分布 $z$ 接近 $p(z)$ 即可。后者可写成</p><script type="math/tex; mode=display">E_{x\sim q(z|x)}p(x|z)</script><p>即普通AE的工作。</p><h3 id="2-SAT"><a href="#2-SAT" class="headerlink" title="2. SAT"></a>2. SAT</h3><p>VAE+GAN的组合并不新鲜，但是这篇文章把它运用于重构图的节点信息，算是一个创新点。$X$表示的是每个node的attribute，$A$是整个图的structure。用两个VAE用于分别重构attribute和structure。其中，$E_x$、$D_x$、$D_A$是MLP，而$E_A$是GNN，其中的原因不是很懂。这篇文章是基于一个假设的，即：</p><blockquote><p>In graph structured data, each node’s attributes and structures are correlated together and can be represented in a shared-latent space.</p></blockquote><p>因为如果不这样，就不能让两个VAE通过隐变量$z$互相学习了。不过这个假设背后的数学原理（是否有），目前还不懂，但这个假设是非常关键的一步。所以$z$其实是一个桥梁，充当了两个角色，1）$E_x-&gt;z-&gt;D_A$和$E_A-&gt;z-&gt;D_x$；2）$z_A$和$z_X$的分布用GAN去拟合。所以这个VAE+GAN和之前有篇VAE-GAN本质上不一样，之前的是用GAN去强化$x$和$\hat x$，使单个VAE的表现更好，图像更清晰，而这篇文章是用GAN去使两个$z$遵从同一分布。</p><p>最后贴一下损失函数作为总结，首先是VAE部分的，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}min_{\theta_x,\theta_a,\phi_x,\phi_a}L_r =&− E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[logp_{\theta_x}(x_i|z_x)]]\\&− E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_a}(a_i|z_a)]]\\&− λ_c · E_{a_i\sim p_A} [E_{q_{\phi_a}(z_a|a_i)}[log p_{\theta_x}(x_i|z_a)]]\\&− λ_c · E_{x_i\sim p_X} [E_{q_{\phi_x}(z_x|x_i)}[log p_{\theta_a}(a_i|z_x)]]\end{split}\nonumber\end{equation}</script><p>其中，$\lambda_c$是调节上下两个的权重的。接下来是GAN的，</p><script type="math/tex; mode=display">\begin{equation}\begin{split}min_\psi max_{\phi_x,\phi_a} L_{adv} = &− E_{z_p\sim p(z)}[log D(z_p)]\\&− E_{z_x\sim q_{\phi_x}(z_x|x_i)}[log(1 − D(z_x))]\\&− E_{z_p\sim p(z)}[log D(z_p)]\\&− E_{z_a\sim q_{\phi_a}(z_a|a_i)}[log(1 − D(z_a))]\end{split}\nonumber\end{equation}</script><p>其中，$\psi$是D的参数，$z_p$是label，来自某个分布，这里是Gaussian。最后是总的。</p><script type="math/tex; mode=display">min_\Theta max_\Phi L = L_r + L_{adv}</script><p>其中，$\Theta = {\theta_x, \theta_a, \phi_x, \phi_a, \psi}$ ，$ Φ = {\phi_x, \phi_a}$。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Introduction&quot;&gt;&lt;a href=&quot;#0-Introduction&quot; class=&quot;headerlink&quot; title=&quot;0. Introduction&quot;&gt;&lt;/a&gt;0. Introduction&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/Le</summary>
      
    
    
    
    <category term="Paper Reading" scheme="https://kang1121.github.io/categories/Paper-Reading/"/>
    
    
    <category term="GNN" scheme="https://kang1121.github.io/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>pip 镜像加速</title>
    <link href="https://kang1121.github.io/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/"/>
    <id>https://kang1121.github.io/2020/03/30/pip-%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/</id>
    <published>2020-03-30T09:24:40.000Z</published>
    <updated>2021-06-30T05:37:30.224Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-临时指定源"><a href="#1-临时指定源" class="headerlink" title="1.临时指定源"></a>1.临时指定源</h3><pre><code class="lang-bash"># xxxxxxx 为安装对象pip install -i https://pypi.tuna.tsinghua.edu.cn/simple xxxxxxx</code></pre><p>&lt;/br&gt;</p><h3 id="2-永久设定"><a href="#2-永久设定" class="headerlink" title="2.永久设定"></a>2.永久设定</h3><pre><code class="lang-bash"> # Linux   下创建或进入 # ~/.pip/pip.conf  [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple # Windows 下创建或进入 # C:/User/xxxxxxx/pip/pip.ini [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-临时指定源&quot;&gt;&lt;a href=&quot;#1-临时指定源&quot; class=&quot;headerlink&quot; title=&quot;1.临时指定源&quot;&gt;&lt;/a&gt;1.临时指定源&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;# xxxxxxx 为安装对象
pip inst</summary>
      
    
    
    
    <category term="Linux" scheme="https://kang1121.github.io/categories/Linux/"/>
    
    
    <category term="下载加速" scheme="https://kang1121.github.io/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>终端加速</title>
    <link href="https://kang1121.github.io/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/"/>
    <id>https://kang1121.github.io/2020/03/30/%E7%BB%88%E7%AB%AF%E5%8A%A0%E9%80%9F/</id>
    <published>2020-03-30T09:05:29.000Z</published>
    <updated>2021-04-19T05:55:08.567Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Port number may vary </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Linux (electron_ssr)</span></span><br><span class="line"><span class="built_in">export</span> http_proxy=http://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> http_proxy=socks5://127.0.0.1:12333</span><br><span class="line"><span class="built_in">export</span> https_proxy=socks5://127.0.0.1:12333</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windows (cmd)(git)</span></span><br><span class="line"><span class="built_in">set</span> http_proxy=http://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> https_proxy=http://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> http_proxy=socks5://127.0.0.1:1080</span><br><span class="line"><span class="built_in">set</span> https_proxy=socks5://127.0.0.1:1080</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=</summary>
      
    
    
    
    <category term="Linux" scheme="https://kang1121.github.io/categories/Linux/"/>
    
    
    <category term="下载加速" scheme="https://kang1121.github.io/tags/%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>LSF 作业调度系统</title>
    <link href="https://kang1121.github.io/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
    <id>https://kang1121.github.io/2020/03/24/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-03-24T01:50:44.000Z</published>
    <updated>2021-06-30T06:26:40.079Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Intro">0. Intro</h3><p>最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。</p><h3 id="1-OS-Software">1. OS &amp; Software</h3><p>Windows 10 ( Linux 下没有 GUI，用 FTP 传文件还是不方便，用 windows 的话就是直接文件交互比较方便 )</p><p>软件用的是 MobaXterm。</p><h3 id="2-Command-List">2. Command List</h3><h4 id="bsub-lsf-sh">bsub &lt; <a href="http://lsf.sh">lsf.sh</a></h4><p>其中， <a href="http://lsf.sh">lsf.sh</a> 是自己写的一个脚本，之前犯错没输 &lt;, 然后提交总是通不过。脚本范例如下：</p><pre><code># !/bin/sh# BSUB -q gpu_v100# BSUB -m "gpu10"# BSUB -gpu num=4:mode=exclusive_process# BSUB -o %J.out# BSUB -n 1# BSUB -e %J.err# BSUB -J Firsttrypython3 /xxx/xxx/xxx/xxx.py</code></pre><h4 id="bjobs">bjobs</h4><p>该指令可以查看当前正在运行的作业。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bjobs.jpg" alt=""></p><h4 id="bjobs-l-JOB-ID">bjobs -l JOB_ID</h4><p>该指令可以查看当前正在运行的作业的详细情况。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bjobs-l.jpg" alt=""></p><h4 id="bjobs-p-JOB-ID">bjobs -p JOB_ID</h4><p>该指令可以查看作业 PENDING 的原因。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bjobs-p.jpg" alt=""></p><h4 id="bkill-JOB-ID">bkill JOB_ID</h4><p>该指令可以结束作业。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bkill.jpg" alt=""></p><h4 id="bkill-r-JOB-ID">bkill -r JOB_ID</h4><p>由于刚接触 LSF，不太了解运行机制。自己写了一些非常烂的程序，提交上去，导致怎么 bkill 都结束不了作业，然后输入 info bkill 查看了一下它的详细用法。这个可以直接杀死进程。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bkill-r.jpg" alt=""></p><h4 id="bstop-JOB-ID-与-bresume-JOB-ID">bstop JOB_ID** 与 **bresume JOB_ID</h4><p>挂起和恢复作业，一般不用。如果作业不想继续了，最好直接 kill，否则占用资源。</p><h4 id="bpeek-JOB-ID-与-bpeek-f-JOB-ID">bpeek JOB_ID 与 bpeek -f JOB_ID</h4><p>该指令可以显示程序当前的屏幕输出。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bpeek.jpg" alt=""></p><h4 id="lsload-与-lsload-gpuload">lsload 与 lsload -gpuload</h4><p>该指令可以输出负载。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/lsload.jpg" alt=""></p><h4 id="bhosts-与-bqueues">bhosts 与 bqueues</h4><p>该指令可以查看各个节点和队列的作业信息。</p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bhosts.jpg" alt=""></p><p><img src="/images/LSF%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/bqueues.jpg" alt=""></p><h3 id="3-Ending">3. Ending</h3><p>最后祝自己以后还有机会用这样的 GPU 集群。:)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Intro&quot;&gt;0. Intro&lt;/h3&gt;
&lt;p&gt;最近在搞 Vehicle Re-Id 的时候，要跑的模型太大，有幸用到了某单位的超算。用的是 LSF 作业调度系统。官方给的指南不太全，自己整理了几个常用的指令。&lt;/p&gt;
&lt;h3 id=&quot;1-OS-Softwar</summary>
      
    
    
    
    <category term="Thinking" scheme="https://kang1121.github.io/categories/Thinking/"/>
    
    
    <category term="LSF" scheme="https://kang1121.github.io/tags/LSF/"/>
    
  </entry>
  
  <entry>
    <title>GAN</title>
    <link href="https://kang1121.github.io/2020/02/17/GAN/"/>
    <id>https://kang1121.github.io/2020/02/17/GAN/</id>
    <published>2020-02-16T15:27:51.000Z</published>
    <updated>2021-06-30T06:28:17.150Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-Description">0. Description</h3><p>这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理.</p><h3 id="1-GAN">1. GAN</h3><p>最初 GAN 的目的是想 generate 出和真实图片非常像的图片. 有个有个图片集 data, 假设它在某维空间满足某个分布:</p><div align="center">     <img src="/images/GAN/1.png" width="50" height="35" align="center"></div><p>但是现在不知道这个分布的 formula, 现在可以做的是从这个 data 的分布中, sample 出一些图片. Generator 就希望能通过 network 学到一个分布:</p><div align="center">     <img src="/images/GAN/2.png" width="33" height="33" align="center"></div><p>希望得到:</p><div align="center">     <img src="/images/GAN/3.png" width="110" height="38" align="center"></div><p>也就是说, 当这两个分布相等时, 随便从 generator 学到的 distribution 中 sample 产生一个图片, 都会是在 data 的distribution 中的, 也就是说会是真实的图片.</p><p>因为 generator 是个 network, 所以它要做的就是学到一个 network, 使得这两个分布的 divergence 最小:</p><div align="center">     <img src="/images/GAN/4.png" width="370" height="40" align="center"></div><p>由于这两个分布它们的 formula 都不知道, 所以 divergence 其实是不能直接算的. 这个时候先把这个问题放一边, 看一下 discriminator.</p><p>Discriminator 要做的事情是区分真实的 image 和 generated 的 image. 如果是从 data distribution 中 sample 出来的, 就给高分; 如果是从 generated distribution 中 sample 出来的, 就给低分:</p><div align="center">     <img src="/images/GAN/7.png" width="265" height="45" align="center"></div><p>所以可以得到以下 cost function, 希望 V 越大越好, 已经经过了一部分等价转换:</p><div align="center">     <img src="/images/GAN/5.png" width="570" height="40" align="center"></div><p>把期望转成积分的形式:</p><div align="center">     <img src="/images/GAN/6.png" width="550" height="42" align="center"></div><p>预期是, 无论输入什么样的 x, 只要来自于 generator 就给低分, 只要来自于 real sample 就给高分, 所以其实 D of x 的在某处(e.g. x = 0)的值不受任何附近(e.g. (-1, 1))的值的影响, 完全可以看成是一元函数求极值.</p><div align="center">     <img src="/images/GAN/8.png" width="270" height="53" align="center"></div><p>最后算出来, 理论上 D 取这个值的时候 V 可以达到最大, 也就是说 discriminator 的性能最好. 但是两个分布都不知道, 所以没有解析解, 真正操作时这个用不了. 但是把上式代入 V 中, 整理后可得:</p><div align="center">     <img src="/images/GAN/9.png" width="600" height="50" align="center"></div><p>发现这个正好是 JS divergence 的形式. 又由于最初要求的就是 g 和 data distribution 的 divergence, 所以把上式代入 G star 得:</p><div align="center">     <img src="/images/GAN/10.png" width="320" height="52" align="center"></div><p>这个式子就可以用 network 求了. 先固定 Generator 训练 Discriminator 让 V 达到 max, 再固定 Discriminator  训练 Generator 使得 V 取最小值. Iteratively 训练.</p><pre><code>import argparseimport osimport numpy as npimport mathimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torch.autograd import Variableimport torch.nn as nnimport torch.nn.functional as Fimport torchos.makedirs("images", exist_ok=True)parser = argparse.ArgumentParser()parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")parser.add_argument("--img_size", type=int, default=28, help="size of each image dimension")parser.add_argument("--channels", type=int, default=1, help="number of image channels")parser.add_argument("--sample_interval", type=int, default=400, help="interval betwen image samples")opt = parser.parse_args()print(opt)img_shape = (opt.channels, opt.img_size, opt.img_size)cuda = True if torch.cuda.is_available() else Falseclass Generator(nn.Module):    def __init__(self):        super(Generator, self).__init__()        def block(in_feat, out_feat, normalize=True):            layers = [nn.Linear(in_feat, out_feat)]            if normalize:                layers.append(nn.BatchNorm1d(out_feat, 0.8))            layers.append(nn.LeakyReLU(0.2, inplace=True))            return layers        self.model = nn.Sequential(            *block(opt.latent_dim, 128, normalize=False),            *block(128, 256),            *block(256, 512),            *block(512, 1024),            nn.Linear(1024, int(np.prod(img_shape))),            nn.Tanh()        )    def forward(self, z):        img = self.model(z)        img = img.view(img.size(0), *img_shape)        return imgclass Discriminator(nn.Module):    def __init__(self):        super(Discriminator, self).__init__()        self.model = nn.Sequential(            nn.Linear(int(np.prod(img_shape)), 512),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(512, 256),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(256, 1),            nn.Sigmoid(),        )    def forward(self, img):        img_flat = img.view(img.size(0), -1)        validity = self.model(img_flat)        return validity# Loss functionadversarial_loss = torch.nn.BCELoss()# Initialize generator and discriminatorgenerator = Generator()discriminator = Discriminator()if cuda:    generator.cuda()    discriminator.cuda()    adversarial_loss.cuda()# Configure data loaderos.makedirs("../../data/mnist", exist_ok=True)dataloader = torch.utils.data.DataLoader(    datasets.MNIST(        "../../data/mnist",        train=True,        download=True,        transform=transforms.Compose(            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]        ),    ),    batch_size=opt.batch_size,    shuffle=True,)# Optimizersoptimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor# ----------#  Training# ----------for epoch in range(opt.n_epochs):    for i, (imgs, _) in enumerate(dataloader):        # Adversarial ground truths        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)        # Configure input        real_imgs = Variable(imgs.type(Tensor))        # -----------------        #  Train Generator        # -----------------        optimizer_G.zero_grad()        # Sample noise as generator input        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))        # Generate a batch of images        gen_imgs = generator(z)        # Loss measures generator's ability to fool the discriminator        g_loss = adversarial_loss(discriminator(gen_imgs), valid)        g_loss.backward()        optimizer_G.step()        # ---------------------        #  Train Discriminator        # ---------------------        optimizer_D.zero_grad()        # Measure discriminator's ability to classify real from generated samples        real_loss = adversarial_loss(discriminator(real_imgs), valid)        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)        d_loss = (real_loss + fake_loss) / 2        d_loss.backward()        optimizer_D.step()        print(            "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())        )        batches_done = epoch * len(dataloader) + i        if batches_done % opt.sample_interval == 0:            save_image(gen_imgs.data[:25], "images/%d.png" % batches_done, nrow=5, normalize=True)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;0-Description&quot;&gt;0. Description&lt;/h3&gt;
&lt;p&gt;这篇 post 将所有了解过的 GAN 都写下来, 方便回忆原理.&lt;/p&gt;
&lt;h3 id=&quot;1-GAN&quot;&gt;1. GAN&lt;/h3&gt;
&lt;p&gt;最初 GAN 的目的是想 generate 出和真实</summary>
      
    
    
    
    <category term="Theoretical Analysis" scheme="https://kang1121.github.io/categories/Theoretical-Analysis/"/>
    
    
  </entry>
  
  <entry>
    <title>sorted 对 class 元素排序</title>
    <link href="https://kang1121.github.io/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/"/>
    <id>https://kang1121.github.io/2020/02/12/sorted%E5%87%BD%E6%95%B0-%E5%AF%B9list-class%E6%8E%92%E5%BA%8F/</id>
    <published>2020-02-12T10:56:02.000Z</published>
    <updated>2021-06-30T05:37:31.845Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><pre><code class="lang-python">class unit(object):    def __init__(self, value, label):        self.value = value        self.label = labela = [unit(None, None) for i in range(1000)]# 对a赋值后# reverse = True 降序, 默认为 False 升序a = sorted(a, key=lambda student: student.value, reverse = True)</code></pre><h3 id="student-可随便换其他名字"><a href="#student-可随便换其他名字" class="headerlink" title="student 可随便换其他名字"></a>student 可随便换其他名字</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Example&quot;&gt;&lt;a href=&quot;#Example&quot; class=&quot;headerlink&quot; title=&quot;Example&quot;&gt;&lt;/a&gt;Example&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;class unit(object):
  </summary>
      
    
    
    
    <category term="Practical Codes" scheme="https://kang1121.github.io/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>mAP CMC</title>
    <link href="https://kang1121.github.io/2020/02/12/mAP-CMC/"/>
    <id>https://kang1121.github.io/2020/02/12/mAP-CMC/</id>
    <published>2020-02-12T10:53:29.000Z</published>
    <updated>2021-06-30T05:37:29.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="mAP-Mean-Average-Precision"><a href="#mAP-Mean-Average-Precision" class="headerlink" title="mAP(Mean Average Precision)"></a>mAP<strong>(Mean Average Precision)</strong></h2><h3 id="0-TP-amp-FN-amp-TN-amp-FP"><a href="#0-TP-amp-FN-amp-TN-amp-FP" class="headerlink" title="0.    TP &amp; FN &amp; TN &amp; FP"></a>0.    TP &amp; FN &amp; TN &amp; FP</h3><h4 id="TP-是-true-positive-表示正样本被判断为正样本-即T-true-FN-是-false-negative-表示-negative-sample-被判断为-positive-sample-即F-false-另外两个也一样"><a href="#TP-是-true-positive-表示正样本被判断为正样本-即T-true-FN-是-false-negative-表示-negative-sample-被判断为-positive-sample-即F-false-另外两个也一样" class="headerlink" title="TP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样."></a>TP 是 true positive, 表示正样本被判断为正样本(即T, true). FN 是 false negative, 表示 negative sample 被判断为 positive sample (即F, false). 另外两个也一样.</h4><h3 id="1-Precision-amp-Recall"><a href="#1-Precision-amp-Recall" class="headerlink" title="1.    Precision &amp; Recall"></a>1.    Precision &amp; Recall</h3><h4 id="分类问题中-现在已有每个样本的概率值和标签-0-1-将样本按照概率从高到底排序-分类器表现理想的情况是-标签为-1-的样本都在上面-标签为-0-的样本都在下面-有个-threshold-一开始指向最上面的-sample-然后每次下移一个-threshold-及以上的都被认为是-positive-sample-下面的都被认为是-negative-sample"><a href="#分类问题中-现在已有每个样本的概率值和标签-0-1-将样本按照概率从高到底排序-分类器表现理想的情况是-标签为-1-的样本都在上面-标签为-0-的样本都在下面-有个-threshold-一开始指向最上面的-sample-然后每次下移一个-threshold-及以上的都被认为是-positive-sample-下面的都被认为是-negative-sample" class="headerlink" title="分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及以上的都被认为是 positive sample, 下面的都被认为是 negative sample."></a>分类问题中, 现在已有每个样本的概率值和标签 (0, 1). 将样本按照概率从高到底排序. 分类器表现理想的情况是, 标签为 1 的样本都在上面, 标签为 0 的样本都在下面. 有个 threshold, 一开始指向最上面的 sample, 然后每次下移一个, threshold 及以上的都被认为是 positive sample, 下面的都被认为是 negative sample.</h4><h4 id="Precision-TP-TP-FN-假设-TP-FN-k-precision-就表示前-k-个样本中-“negative-sample-的比例”-因为它们本来应该呆在-positive-sample-下面的-但它们现在跑到-positive-sample-上面去了-有几个-positive-sample-就计算几个-precision-threshold-每次下移一个-当移到某个-sample-为-positive-sample-的时候再算-precision"><a href="#Precision-TP-TP-FN-假设-TP-FN-k-precision-就表示前-k-个样本中-“negative-sample-的比例”-因为它们本来应该呆在-positive-sample-下面的-但它们现在跑到-positive-sample-上面去了-有几个-positive-sample-就计算几个-precision-threshold-每次下移一个-当移到某个-sample-为-positive-sample-的时候再算-precision" class="headerlink" title="Precision = TP / (TP + FN)    假设 TP + FN = k, precision 就表示前 k 个样本中, “negative sample 的比例”, 因为它们本来应该呆在 positive sample 下面的, 但它们现在跑到 positive sample 上面去了. 有几个 positive sample 就计算几个 precision, threshold 每次下移一个, 当移到某个 sample 为 positive sample 的时候再算 precision."></a>Precision = TP / (TP + FN)    假设 TP + FN = k, precision 就表示前 k 个样本中, “negative sample 的比例”, 因为它们本来应该呆在 positive sample 下面的, 但它们现在跑到 positive sample 上面去了. 有几个 positive sample 就计算几个 precision, threshold 每次下移一个, 当移到某个 sample 为 positive sample 的时候再算 precision.</h4><h4 id="Recall-TP-TP-FP-表示-positive-sample-被成功找回来的概率-因为-positive-sample-总数不变-所以-TP-FP-不变-Recall-最终会为1"><a href="#Recall-TP-TP-FP-表示-positive-sample-被成功找回来的概率-因为-positive-sample-总数不变-所以-TP-FP-不变-Recall-最终会为1" class="headerlink" title="Recall = TP / (TP + FP)     表示 positive sample 被成功找回来的概率. 因为 positive sample 总数不变, 所以 TP + FP 不变. Recall 最终会为1."></a>Recall = TP / (TP + FP)     表示 positive sample 被成功找回来的概率. 因为 positive sample 总数不变, 所以 TP + FP 不变. Recall 最终会为1.</h4><h3 id="2-AP-amp-mAP"><a href="#2-AP-amp-mAP" class="headerlink" title="2.    AP &amp; mAP"></a>2.    AP &amp; mAP</h3><h4 id="假设有"><a href="#假设有" class="headerlink" title="假设有"></a>假设有</h4><script type="math/tex; mode=display">AP =\frac{\sum^N_1 precision}{N}</script><p>&lt;/br&gt;</p><h2 id="CMC-Cumulative-Match-Characteristics"><a href="#CMC-Cumulative-Match-Characteristics" class="headerlink" title="CMC(Cumulative Match Characteristics)"></a>CMC<strong>(Cumulative Match Characteristics)</strong></h2><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><p>&lt;/br&gt;</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;mAP-Mean-Average-Precision&quot;&gt;&lt;a href=&quot;#mAP-Mean-Average-Precision&quot; class=&quot;headerlink&quot; title=&quot;mAP(Mean Average Precision)&quot;&gt;&lt;/a&gt;mAP&lt;str</summary>
      
    
    
    
    <category term="Metrics" scheme="https://kang1121.github.io/categories/Metrics/"/>
    
    
  </entry>
  
  <entry>
    <title>Image.convert转化图片</title>
    <link href="https://kang1121.github.io/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/"/>
    <id>https://kang1121.github.io/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/</id>
    <published>2019-12-20T11:19:34.000Z</published>
    <updated>2021-04-19T06:04:44.735Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1 ------------------（1位像素，黑白，每字节一个像素存储）</span><br><span class="line">L ------------------（8位像素，黑白）</span><br><span class="line">P ------------------（8位像素，使用调色板映射到任何其他模式）</span><br><span class="line">RGB-------------- （3x8位像素，真彩色）</span><br><span class="line">RGBA-------------（4x8位像素，带透明度掩模的真彩色）</span><br><span class="line">CMYK-------------（4x8位像素，分色）</span><br><span class="line">YCbCr------------ （3x8位像素，彩色视频格式）</span><br><span class="line">I--------------------（32位有符号整数像素）</span><br><span class="line">F------------------- （32位浮点像素）</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'1'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/a.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'L'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/b.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'P'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/c.png" width="320" height="240" align="center"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; Image.open(path).convert(&#39;RGB&#39;)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/d.png" width="320" height="240" align="center"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; Image.open(path).convert(&#39;RGBA&#39;)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/e.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'CMYK'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/f.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'YCbCr'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/g.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'I'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/h.png" width="320" height="240" align="center"></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = Image.open(path).convert(<span class="string">'F'</span>)</span><br></pre></td></tr></table></figure><div align="center">     <img src="/images/Image.convert转化图片/k.png" width="320" height="240" align="center"></div>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class</summary>
      
    
    
    
    <category term="Practical Codes" scheme="https://kang1121.github.io/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>模型的保存与载入</title>
    <link href="https://kang1121.github.io/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/"/>
    <id>https://kang1121.github.io/2019/12/19/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%BD%BD%E5%85%A5/</id>
    <published>2019-12-19T10:02:48.000Z</published>
    <updated>2021-06-30T05:37:37.290Z</updated>
    
    <content type="html"><![CDATA[<h3 id="跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。"><a href="#跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。" class="headerlink" title="跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。"></a>跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。</h3><p>&lt;/br&gt;</p><h3 id="保存："><a href="#保存：" class="headerlink" title="保存："></a>保存：</h3><pre><code class="lang-python">torch.save(net.state_dict(), model_path + '/model-inter-' + str(batch_id+1) + ".pt")</code></pre><p>&lt;/br&gt;</p><h3 id="加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错："><a href="#加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错：" class="headerlink" title="加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错："></a>加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：</h3><pre><code class="lang-python">net = Siamese()net.load_state_dict(torch.load('/home/yk/siamese-pytorch/models/model-inter-104001.pt', map_location='cuda:0')</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。&quot;</summary>
      
    
    
    
    <category term="Practical Codes" scheme="https://kang1121.github.io/categories/Practical-Codes/"/>
    
    
    <category term="Pytorch" scheme="https://kang1121.github.io/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>制作自己的 dataset</title>
    <link href="https://kang1121.github.io/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/"/>
    <id>https://kang1121.github.io/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/</id>
    <published>2019-12-01T10:34:03.000Z</published>
    <updated>2021-06-30T05:36:49.430Z</updated>
    
    <content type="html"><![CDATA[<h3 id="制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。"><a href="#制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。" class="headerlink" title="制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader  封装就好了。"></a>制作自己的 dataset 要写一个自己的 Dataset 类，然后用 Dataloader  封装就好了。</h3><hr><h1 id="一、Dataset-制作"><a href="#一、Dataset-制作" class="headerlink" title="一、Dataset 制作"></a>一、Dataset 制作</h1><h3 id="一般-Dataset-类有以下的函数："><a href="#一般-Dataset-类有以下的函数：" class="headerlink" title="一般 Dataset 类有以下的函数："></a>一般 Dataset 类有以下的函数：</h3><pre><code class="lang-python">class Dataset(Dataset):    def __init__(self, ...):        ...    def __getitem__(self, index):        ...    def __len__(self):        ...</code></pre><p>&lt;/br&gt;</p><h3 id="init-是初始化时传入的一些参数，不是非常重要。"><a href="#init-是初始化时传入的一些参数，不是非常重要。" class="headerlink" title="__init__() 是初始化时传入的一些参数，不是非常重要。"></a>__init__() 是初始化时传入的一些参数，不是非常重要。</h3><h3 id="getitem-需要自己修改，功能是将图片从磁盘中读入，存入-array-或者-list-中。"><a href="#getitem-需要自己修改，功能是将图片从磁盘中读入，存入-array-或者-list-中。" class="headerlink" title="__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。"></a>__getitem__() 需要自己修改，功能是将图片从磁盘中读入，存入 array 或者 list 中。</h3><h3 id="len-是返回-Dataset-的大小，需要仔细设计。"><a href="#len-是返回-Dataset-的大小，需要仔细设计。" class="headerlink" title="__len()__ 是返回 Dataset 的大小，需要仔细设计。"></a>__len()__ 是返回 Dataset 的大小，需要仔细设计。</h3><h3 id="下面是两个用于构建Siamese-Nerual-Network-的-example-。"><a href="#下面是两个用于构建Siamese-Nerual-Network-的-example-。" class="headerlink" title="下面是两个用于构建Siamese Nerual Network 的 example 。"></a>下面是两个用于构建Siamese Nerual Network 的 example 。</h3><h3 id="这个是事先将图片的-path-都写入了一个-txt-文件中，然后-getitem-就从-txt-中读图片路径。"><a href="#这个是事先将图片的-path-都写入了一个-txt-文件中，然后-getitem-就从-txt-中读图片路径。" class="headerlink" title="这个是事先将图片的 path 都写入了一个 txt 文件中，然后 getitem 就从 txt 中读图片路径。"></a>这个是事先将图片的 path 都写入了一个 txt 文件中，然后 getitem 就从 txt 中读图片路径。</h3><pre><code class="lang-python">class MyDataset(Dataset):    def __init__(self, txt, transform=None, target_transform=None, should_invert=False):        self.transform = transform        self.target_transform = target_transform        self.should_invert = should_invert        self.txt = txt    def __getitem__(self, index):        line = linecache.getline(self.txt, random.randint(1, self.__len__()))        line.strip('\n')        img0_list = line.split()        # 判断是否要选同一个类别的图片        should_get_same_class = random.randint(0, 1)        if should_get_same_class:            while True:                # 随机在 txt 中选一行读取，每一行有一张图片的 path 和它的 label                img1_list = linecache.getline(self.txt, random.randint(1, self.__len__())).strip('\n').split()                if img0_list[1] == img1_list[1]:                    break        else:            img1_list = linecache.getline(self.txt, random.randint(1, self.__len__())).strip('\n').split()        img0 = Image.open(img0_list[0])        img1 = Image.open(img1_list[0])        # 转图片通道数        img0 = img0.convert("L")        img1 = img1.convert("L")        # 非必要的        if self.should_invert:            img0 = PIL.ImageOps.invert(img0)            img1 = PIL.ImageOps.invert(img1)        # 非必要的        if self.transform is not None:            img0 = self.transform(img0)            img1 = self.transform(img1)        return img0, img1, torch.from_numpy(np.array([int(img1_list[1] != img0_list[1])], dtype=np.float32))    # 这个 len 的返回长度就是 txt 中图片总数    def __len__(self):        fh = open(self.txt, 'r')        num = len(fh.readlines())        fh.close()        return num</code></pre><p>&lt;/br&gt;</p><h3 id="这个是事先没有准备-txt-目录，所以写了一个-loadToMem-去每个文件夹里面找图片。"><a href="#这个是事先没有准备-txt-目录，所以写了一个-loadToMem-去每个文件夹里面找图片。" class="headerlink" title="这个是事先没有准备 txt 目录，所以写了一个 loadToMem 去每个文件夹里面找图片。"></a>这个是事先没有准备 txt 目录，所以写了一个 loadToMem 去每个文件夹里面找图片。</h3><pre><code class="lang-python">class OmniglotTest(Dataset):    def __init__(self, dataPath, transform=None, times=100, way=166):        np.random.seed(1)        super(OmniglotTest, self).__init__()        self.transform = transform        self.times = times        self.way = way        self.img1 = None        self.c1 = None        self.datas, self.num_classes = self.loadToMem(dataPath)    def loadToMem(self, dataPath):        print("begin loading test dataset to memory")        # datas 是读取到的图片的总 list，idx 是类别数。        datas = {}        idx = 0        for alphaPath in os.listdir(dataPath):            # for charPath in os.listdir(os.path.join(dataPath, alphaPath)):                datas[idx] = []                for samplePath in os.listdir(os.path.join(dataPath, alphaPath)):                    filePath = os.path.join(dataPath, alphaPath, samplePath)                    s = Image.open(filePath).convert('L')                    # 调整图片尺寸                    s = s.resize((105, 105), Image.ANTIALIAS)                    datas[idx].append(s)                idx += 1        print("finish loading test dataset to memory")        return datas, idx    def __len__(self):        return self.times * self.way    def __getitem__(self, index):        idx = index % self.way        label = None        # generate image pair from same class        if idx == 0:            self.c1 = random.randint(0, self.num_classes - 1)            self.img1 = random.choice(self.datas[self.c1])            img2 = random.choice(self.datas[self.c1])        # generate image pair from different class        else:            c2 = random.randint(0, self.num_classes - 1)            while self.c1 == c2:                c2 = random.randint(0, self.num_classes - 1)            img2 = random.choice(self.datas[c2])        if self.transform:            img1 = self.transform(self.img1)            img2 = self.transform(img2)        # print('datas.shape = ', len(self.datas))        # print('img1 = ', img1.shape)        # print('img2 = ', img2.shape)        return img1, img2</code></pre><p>&lt;/br&gt;</p><hr><h1 id="二、Dataloader-封装"><a href="#二、Dataloader-封装" class="headerlink" title="二、Dataloader 封装"></a>二、Dataloader 封装</h1><h3 id="这个比较简单，因为-Dataloader-是-Pytorch-内置的函数。"><a href="#这个比较简单，因为-Dataloader-是-Pytorch-内置的函数。" class="headerlink" title="这个比较简单，因为 Dataloader 是 Pytorch 内置的函数。"></a>这个比较简单，因为 Dataloader 是 Pytorch 内置的函数。</h3><pre><code class="lang-python">train_dataloader = DataLoader(dataset=train_data, shuffle=True, num_workers=2, batch_size=Config.train_batch_size)</code></pre><p>&lt;/br&gt;</p><h3 id="主要需要关注的是-batch-size-。这个以及之前提到的-len-和训练的次数有关。"><a href="#主要需要关注的是-batch-size-。这个以及之前提到的-len-和训练的次数有关。" class="headerlink" title="主要需要关注的是 batch_size 。这个以及之前提到的 len 和训练的次数有关。"></a>主要需要关注的是 batch_size 。这个以及之前提到的 len 和训练的次数有关。</h3><pre><code class="lang-python">for i, data in enumerate(train_dataloader, 0):</code></pre><p>&lt;/br&gt;</p><h3 id="其中，for-循环的次数-len-batch-size-。"><a href="#其中，for-循环的次数-len-batch-size-。" class="headerlink" title="其中，for 循环的次数 = len / batch_size 。"></a>其中，for 循环的次数 = len / batch_size 。</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。&quot;&gt;&lt;a href=&quot;#制作自己的-dataset-要写一个自己的-Dataset-类，然后用-Dataloader-封装就好了。&quot; class=&quot;heade</summary>
      
    
    
    
    <category term="Practical Codes" scheme="https://kang1121.github.io/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>RuntimeError: size mismatch, m1: [128 x 184320], m2: [9216 x 4096]</title>
    <link href="https://kang1121.github.io/2019/11/30/size-mismatch/"/>
    <id>https://kang1121.github.io/2019/11/30/size-mismatch/</id>
    <published>2019-11-30T07:42:55.000Z</published>
    <updated>2021-06-30T05:40:44.189Z</updated>
    
    <content type="html"><![CDATA[<h3 id="今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。"><a href="#今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。" class="headerlink" title="今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。"></a>今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。</h3><h3 id="卷积层结果一般是-batchsize-dimension0-1-1-，-全连接层只有二维-batchsize-dimensio-0-，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是-batchsize-dimension-0-1-1-的形式，就不会被压缩成-batchsize-dimension-0-的形式，而是别的形式。下面就算不下去了。"><a href="#卷积层结果一般是-batchsize-dimension0-1-1-，-全连接层只有二维-batchsize-dimensio-0-，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是-batchsize-dimension-0-1-1-的形式，就不会被压缩成-batchsize-dimension-0-的形式，而是别的形式。下面就算不下去了。" class="headerlink" title="卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。"></a>卷积层结果一般是 [batchsize, dimension0, 1, 1]， 全连接层只有二维 [batchsize, dimensio_0]，会自动对之前四维的卷积结果进行压缩。如果最后卷积结果不是 [batchsize, dimension_0, 1, 1] 的形式，就不会被压缩成 [batchsize, dimension_0] 的形式，而是别的形式。下面就算不下去了。</h3><p>&lt;/br&gt;</p><p><img src="/images/size-mismatch/1.png" alt=""></p><p>&lt;/br&gt;</p><h3 id="像下图这个网络参数对应的输入图像尺寸应该是-105-x-105-的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。"><a href="#像下图这个网络参数对应的输入图像尺寸应该是-105-x-105-的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。" class="headerlink" title="像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。"></a>像下图这个网络参数对应的输入图像尺寸应该是 105 x 105 的，但是我在预处理的时候没考虑到这点，虽然事后可以debug出来，但是应该事先要考虑到这点。</h3><p>&lt;/br&gt;</p><p><img src="/images/size-mismatch/3.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;今天跑代码遇到这个问题，发现出错的位置是在卷积层到全连接层的地方。卷积网络的每层节点个数都是事先定好的，这对input的像素也有要求，必须也是和预先设定的像素相同，否则卷积层最后得出的结果会与设计的不同。&quot;&gt;&lt;a href=&quot;#今天跑代码遇到这个问题，发现出错的位</summary>
      
    
    
    
    <category term="Thinking" scheme="https://kang1121.github.io/categories/Thinking/"/>
    
    
    <category term="Python错误" scheme="https://kang1121.github.io/tags/Python%E9%94%99%E8%AF%AF/"/>
    
  </entry>
  
  <entry>
    <title>将dataset标签写入txt</title>
    <link href="https://kang1121.github.io/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/"/>
    <id>https://kang1121.github.io/2019/11/26/%E5%B0%86dataset%E6%A0%87%E7%AD%BE%E5%86%99%E5%85%A5txt/</id>
    <published>2019-11-26T10:26:15.000Z</published>
    <updated>2021-06-30T05:37:36.076Z</updated>
    
    <content type="html"><![CDATA[<h3 id="从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签："><a href="#从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：" class="headerlink" title="从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签："></a>从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个 label.txt 方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：</h3><p>&lt;/br&gt;</p><p><img src="/images/将dataset标签写入txt/1.png" alt=""></p><p>&lt;/br&gt;</p><h3 id="因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。"><a href="#因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。" class="headerlink" title="因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。"></a>因为我原先的这个数据集里面每类样本数不一样，所以稍微要烦一丢丢，直接上代码。</h3><p>&lt;/br&gt;</p><pre><code class="lang-python">import osroots = "/home/yk/下载/VERI-Wild/images/"                def convert(train=True):    if train:        f = open(roots + 'train.txt', 'w')            # 新建了一个train.txt存label的信息        data_path = roots + 'images/'                    if not os.path.exists(data_path):            os.makedirs(data_path)        label = 0        for root, dirs, files in os.walk(data_path):            if len(dirs):                # print(dirs)                continue            else:                label = label + 1                s = len(files)                for i in range(s):                    img_path = root + '/' + files[i]                    # print(img_path + ' ' + str(label))                    f.write(img_path + ' ' + str(label) + '\n')            # 写入文件        f.close()convert(train=True)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练。比如像这样的，第一列是图片位置，第二列是标签：&quot;&gt;&lt;a href=&quot;#从网上获取的数据集，想做成自己想要的样子，要为该数据集做一个-label-txt-方便以后的训练</summary>
      
    
    
    
    <category term="Practical Codes" scheme="https://kang1121.github.io/categories/Practical-Codes/"/>
    
    
  </entry>
  
  <entry>
    <title>删除错误的更新源</title>
    <link href="https://kang1121.github.io/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/"/>
    <id>https://kang1121.github.io/2019/11/26/%E5%88%A0%E9%99%A4%E9%94%99%E8%AF%AF%E7%9A%84%E6%9B%B4%E6%96%B0%E6%BA%90/</id>
    <published>2019-11-26T09:44:59.000Z</published>
    <updated>2021-06-30T05:37:38.618Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linux在执行-apt-get-update时，有的时候会出现这样的情况。"><a href="#Linux在执行-apt-get-update时，有的时候会出现这样的情况。" class="headerlink" title="Linux在执行 apt-get update时，有的时候会出现这样的情况。"></a>Linux在执行 apt-get update时，有的时候会出现这样的情况。</h3><h3 id="lt-br-gt"><a href="#lt-br-gt" class="headerlink" title="</br>"></a>&lt;/br&gt;</h3><p><img src="/images/删除错误的更新源/1.png" alt=""></p><p>&lt;/br&gt;</p><h3 id="之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入-etc-apt-sources-list-d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。"><a href="#之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入-etc-apt-sources-list-d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。" class="headerlink" title="之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。"></a>之后每次对新的软件更新都会看到之前的错误提示，很烦。所以要把这些一直更新错误的软件信息删去。如下图操作，进入/etc/apt/sources.list.d，输入ls查看，可以看到上图中更新错误的hzwhuang-ubuntu-ss-qt5。</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/2.png" alt=""></p><p>&lt;/br&gt;</p><h3 id="输入-sudo-rm-XXXXX-文件名-，就可以删除该文件，把相关的list、save文件一并删除。"><a href="#输入-sudo-rm-XXXXX-文件名-，就可以删除该文件，把相关的list、save文件一并删除。" class="headerlink" title="输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。"></a>输入 sudo rm XXXXX(文件名)，就可以删除该文件，把相关的list、save文件一并删除。</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/3.png" alt=""></p><p>&lt;/br&gt;</p><h3 id="这时再-apt-get-update-时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！"><a href="#这时再-apt-get-update-时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！" class="headerlink" title="这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！"></a>这时再 apt-get update 时，刚刚那个错误就消失了。就这样，把所有的之前更新不了的软件信息都删掉，心旷神怡！！！</h3><p>&lt;/br&gt;</p><p><img src="/images/删除错误的更新源/6.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Linux在执行-apt-get-update时，有的时候会出现这样的情况。&quot;&gt;&lt;a href=&quot;#Linux在执行-apt-get-update时，有的时候会出现这样的情况。&quot; class=&quot;headerlink&quot; title=&quot;Linux在执行 apt-get</summary>
      
    
    
    
    <category term="Linux" scheme="https://kang1121.github.io/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>使用Github+Hexo搭建Blog</title>
    <link href="https://kang1121.github.io/2019/11/24/first-time-record/"/>
    <id>https://kang1121.github.io/2019/11/24/first-time-record/</id>
    <published>2019-11-24T10:25:46.000Z</published>
    <updated>2021-04-19T06:03:49.220Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Happy"><a href="#Happy" class="headerlink" title="Happy."></a>Happy.</h3><p><img src="/images/c.jpg" alt></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Happy&quot;&gt;&lt;a href=&quot;#Happy&quot; class=&quot;headerlink&quot; title=&quot;Happy.&quot;&gt;&lt;/a&gt;Happy.&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/images/c.jpg&quot; alt&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Thinking" scheme="https://kang1121.github.io/categories/Thinking/"/>
    
    
    <category term="Life" scheme="https://kang1121.github.io/tags/Life/"/>
    
  </entry>
  
</feed>
