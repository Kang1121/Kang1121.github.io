<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>模型的保存与载入</title><meta name="description" content="My blog"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。&amp;lt;/br&amp;gt;
保存：torch.save(net.state_dict(), model_path + '/model-inter-' + str(batch_id+1) + &quot;.pt&quot;)

&amp;lt;/br&amp;gt;
加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：net = Siamese()
net.load_state_dict(torch.load('/home/yk/siam.."><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Kang's blog" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Kang Yin's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">模型的保存与载入</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%91%E5%A4%A7%E7%BD%91%E7%BB%9C%E4%B8%80%E6%AC%A1%E8%B7%91%E4%B8%8D%E5%AE%8C%EF%BC%8C%E5%B0%B1%E8%A6%81%E4%BF%9D%E5%AD%98%E4%BA%86%E4%B8%8B%E6%AC%A1%E5%86%8D%E8%B7%91%E3%80%82%E6%9C%89%E4%B8%A4%E7%A7%8D%E4%BF%9D%E5%AD%98%E6%96%B9%E5%BC%8F%EF%BC%8C%E4%B8%80%E7%A7%8D%E6%98%AF%E4%BF%9D%E5%AD%98%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84-e-g-%E6%AF%8F%E5%B1%82%E7%9A%84W-b-%EF%BC%8C%E4%B8%80%E7%A7%8D%E6%98%AF%E6%95%B4%E4%B8%AA%E7%BD%91%E7%BB%9C%E6%89%80%E6%9C%89%E4%B8%9C%E8%A5%BF%E5%85%A8%E9%83%A8%E4%BF%9D%E5%AD%98%E3%80%82%E7%BD%91%E4%B8%8A%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E7%AC%AC%E4%B8%80%E7%A7%8D%EF%BC%8C%E5%9B%A0%E4%B8%BA%E5%A6%82%E6%9E%9C%E7%BD%91%E7%BB%9C%E8%BF%87%E5%A4%A7%EF%BC%8C%E7%94%A8%E7%AC%AC%E4%BA%8C%E7%A7%8D%E6%96%B9%E6%B3%95%E5%8A%A0%E8%BD%BD%E7%BD%91%E7%BB%9C%E4%BC%9A%E6%AF%94%E8%BE%83%E6%85%A2%EF%BC%8C%E8%80%8C%E4%B8%94%E5%8D%A0%E5%9C%B0%E6%96%B9%E4%B9%9F%E5%A4%A7%E3%80%82%E6%88%91%E5%8F%AA%E8%AF%95%E8%BF%87%E7%AC%AC%E4%B8%80%E7%A7%8D%EF%BC%8CPytorch-%E4%BE%8B%E5%AD%90%E5%A6%82%E4%B8%8B%E3%80%82"><span class="toc-text">跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%EF%BC%9A"><span class="toc-text">保存：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%EF%BC%8C-map-location-%E8%A6%81%E5%86%99%E6%B8%85%E6%A5%9A%E7%94%A8%E7%9A%84%E6%98%AF-CPU-%E8%BF%98%E6%98%AF-GPU%EF%BC%8C%E7%94%A8%E7%9A%84%E6%98%AF%E5%93%AA%E5%87%A0%E5%9D%97%EF%BC%8C%E4%B8%8D%E7%84%B6%E5%8F%AF%E8%83%BD%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%9A"><span class="toc-text">加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Pytorch"><i class="tag post-item-tag">Pytorch</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">模型的保存与载入</h1><time class="has-text-grey" datetime="2019-12-19T10:02:48.000Z">2019-12-19</time><article class="mt-2 post-content"><h3 id="跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。"><a href="#跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构-e-g-每层的W-b-，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch-例子如下。" class="headerlink" title="跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。"></a>跑大网络一次跑不完，就要保存了下次再跑。有两种保存方式，一种是保存网络基本结构(e.g. 每层的W, b)，一种是整个网络所有东西全部保存。网上推荐使用第一种，因为如果网络过大，用第二种方法加载网络会比较慢，而且占地方也大。我只试过第一种，Pytorch 例子如下。</h3><p>&lt;/br&gt;</p>
<h3 id="保存："><a href="#保存：" class="headerlink" title="保存："></a>保存：</h3><pre><code class="lang-python">torch.save(net.state_dict(), model_path + '/model-inter-' + str(batch_id+1) + ".pt")
</code></pre>
<p>&lt;/br&gt;</p>
<h3 id="加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错："><a href="#加载，-map-location-要写清楚用的是-CPU-还是-GPU，用的是哪几块，不然可能会报错：" class="headerlink" title="加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错："></a>加载， map_location 要写清楚用的是 CPU 还是 GPU，用的是哪几块，不然可能会报错：</h3><pre><code class="lang-python">net = Siamese()
net.load_state_dict(torch.load('/home/yk/siamese-pytorch/models/model-inter-104001.pt', map_location='cuda:0')
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2019/12/20/Image-convert%E8%BD%AC%E5%8C%96%E5%9B%BE%E7%89%87/" title="Image.convert转化图片"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: Image.convert转化图片</span></a><a class="button is-default" href="/2019/12/01/%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84dataset/" title="制作自己的 dataset"><span class="has-text-weight-semibold">Next: 制作自己的 dataset</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Kang1121/Kang1121.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/kang1121"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/kang.97kk/?hl=zh-cn"><i class="iconfont icon-ins"></i></a><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/康-殷-33665b15a"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--></section><p><span>Copyright ©</span><span> Kang Yin 2021</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>